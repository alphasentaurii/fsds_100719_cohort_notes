{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sect 46: Tuning Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Study Group: 02-12-20\n",
    "- online-ds-ft-100719"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Announcements/Choices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **When/if to cover PySpark sections (sect 40 & 41)?**\n",
    "    - Capstone starts next week.\n",
    "    - Two Sections require PySpark/Docker.\n",
    "        - (Honestly it just does enough to check the box of having covered it, but that's it.)\n",
    "- **One alternative option: give you the Deep Learning Project from curric v1.1** and talk through how to tackle it\n",
    "- **Section 50: Amazon Web Services**\n",
    "    - Let's save it for a couple weeks into capstone and use it in order to set up storage for web-dashboards deployed with dash/plotly and herokuapp."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Revisit neural networks powerpoint with updated images to review biological inspiration of ANNs**\n",
    "- **Discuss details about deep neural networks:**\n",
    "    - what makes an ANN \"deep\"?\n",
    "    - what are the different activation functions?\n",
    "    - how do we do hyperparameter tuning/grid-searching?\n",
    "- **Discuss/demo using Keras neural network for image classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Functions\n",
    "- https://dashee87.github.io/deep%20learning/visualising-activation-functions-in-neural-networks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T19:10:40.392381Z",
     "start_time": "2020-02-13T19:10:39.824186Z"
    },
    "code_folding": [
     4,
     10,
     16,
     32,
     48,
     53
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def sigmoid(x, derivative=False):\n",
    "    f = 1 / (1 + np.exp(-x))\n",
    "    if (derivative == True):\n",
    "        return f * (1 - f)\n",
    "    return f\n",
    "\n",
    "def tanh(x, derivative=False):\n",
    "    f = np.tanh(x)\n",
    "    if (derivative == True):\n",
    "        return (1 - (f ** 2))\n",
    "    return np.tanh(x)\n",
    "\n",
    "def relu(x, derivative=False):\n",
    "    f = np.zeros(len(x))\n",
    "    if (derivative == True):\n",
    "        for i in range(0, len(x)):\n",
    "            if x[i] > 0:\n",
    "                f[i] = 1  \n",
    "            else:\n",
    "                f[i] = 0\n",
    "        return f\n",
    "    for i in range(0, len(x)):\n",
    "        if x[i] > 0:\n",
    "            f[i] = x[i]  \n",
    "        else:\n",
    "            f[i] = 0\n",
    "    return f\n",
    "\n",
    "def leaky_relu(x, leakage = 0.05, derivative=False):\n",
    "    f = np.zeros(len(x))\n",
    "    if (derivative == True):\n",
    "        for i in range(0, len(x)):\n",
    "            if x[i] > 0:\n",
    "                f[i] = 1  \n",
    "            else:\n",
    "                f[i] = leakage\n",
    "        return f\n",
    "    for i in range(0, len(x)):\n",
    "        if x[i] > 0:\n",
    "            f[i] = x[i]  \n",
    "        else:\n",
    "            f[i] = x[i]* leakage\n",
    "    return f\n",
    "\n",
    "def arctan(x, derivative=False):\n",
    "    if (derivative == True):\n",
    "        return 1/(1+np.square(x))\n",
    "    return np.arctan(x)\n",
    "\n",
    "def plot_activation(fn):\n",
    "    z = np.arange(-10, 10, 0.2)\n",
    "    y = fn(z)\n",
    "    dy = fn(z, derivative=True)\n",
    "    fig,ax=plt.subplots(figsize=(6,4))\n",
    "    ax.set_title(f'{fn.__name__}')\n",
    "    ax.set(xlabel='Input',ylabel='Output')\n",
    "    ax.axhline(color='gray', linewidth=1,)\n",
    "    ax.axvline(color='gray', linewidth=1,)\n",
    "    ax.plot(z, y, 'r', label='original (y)')\n",
    "    ax.plot(z, dy, 'b', label='derivative (dy)')\n",
    "    ax.legend();\n",
    "    plt.show()\n",
    "\n",
    "## Plot activation functions\n",
    "# act_funcs = [sigmoid,tanh,arctan,relu,leaky_relu]\n",
    "# [plot_activation(fn) for fn in act_funcs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Classification with MLPs - Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T19:10:44.169288Z",
     "start_time": "2020-02-13T19:10:40.394108Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fsds_1007219  v0.7.4 loaded.  Read the docs: https://fsds.readthedocs.io/en/latest/ \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_871fc51a_4e94_11ea_a34a_4865ee12e626\" ><caption>Loaded Packages and Handles</caption><thead>    <tr>        <th class=\"col_heading level0 col0\" >Handle</th>        <th class=\"col_heading level0 col1\" >Package</th>        <th class=\"col_heading level0 col2\" >Description</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_871fc51a_4e94_11ea_a34a_4865ee12e626row0_col0\" class=\"data row0 col0\" >dp</td>\n",
       "                        <td id=\"T_871fc51a_4e94_11ea_a34a_4865ee12e626row0_col1\" class=\"data row0 col1\" >IPython.display</td>\n",
       "                        <td id=\"T_871fc51a_4e94_11ea_a34a_4865ee12e626row0_col2\" class=\"data row0 col2\" >Display modules with helpful display and clearing commands.</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_871fc51a_4e94_11ea_a34a_4865ee12e626row1_col0\" class=\"data row1 col0\" >fs</td>\n",
       "                        <td id=\"T_871fc51a_4e94_11ea_a34a_4865ee12e626row1_col1\" class=\"data row1 col1\" >fsds_100719</td>\n",
       "                        <td id=\"T_871fc51a_4e94_11ea_a34a_4865ee12e626row1_col2\" class=\"data row1 col2\" >Custom data science bootcamp student package</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_871fc51a_4e94_11ea_a34a_4865ee12e626row2_col0\" class=\"data row2 col0\" >mpl</td>\n",
       "                        <td id=\"T_871fc51a_4e94_11ea_a34a_4865ee12e626row2_col1\" class=\"data row2 col1\" >matplotlib</td>\n",
       "                        <td id=\"T_871fc51a_4e94_11ea_a34a_4865ee12e626row2_col2\" class=\"data row2 col2\" >Matplotlib's base OOP module with formatting artists</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_871fc51a_4e94_11ea_a34a_4865ee12e626row3_col0\" class=\"data row3 col0\" >plt</td>\n",
       "                        <td id=\"T_871fc51a_4e94_11ea_a34a_4865ee12e626row3_col1\" class=\"data row3 col1\" >matplotlib.pyplot</td>\n",
       "                        <td id=\"T_871fc51a_4e94_11ea_a34a_4865ee12e626row3_col2\" class=\"data row3 col2\" >Matplotlib's matlab-like plotting module</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_871fc51a_4e94_11ea_a34a_4865ee12e626row4_col0\" class=\"data row4 col0\" >np</td>\n",
       "                        <td id=\"T_871fc51a_4e94_11ea_a34a_4865ee12e626row4_col1\" class=\"data row4 col1\" >numpy</td>\n",
       "                        <td id=\"T_871fc51a_4e94_11ea_a34a_4865ee12e626row4_col2\" class=\"data row4 col2\" >scientific computing with Python</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_871fc51a_4e94_11ea_a34a_4865ee12e626row5_col0\" class=\"data row5 col0\" >pd</td>\n",
       "                        <td id=\"T_871fc51a_4e94_11ea_a34a_4865ee12e626row5_col1\" class=\"data row5 col1\" >pandas</td>\n",
       "                        <td id=\"T_871fc51a_4e94_11ea_a34a_4865ee12e626row5_col2\" class=\"data row5 col2\" >High performance data structures and tools</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_871fc51a_4e94_11ea_a34a_4865ee12e626row6_col0\" class=\"data row6 col0\" >sns</td>\n",
       "                        <td id=\"T_871fc51a_4e94_11ea_a34a_4865ee12e626row6_col1\" class=\"data row6 col1\" >seaborn</td>\n",
       "                        <td id=\"T_871fc51a_4e94_11ea_a34a_4865ee12e626row6_col2\" class=\"data row6 col2\" >High-level data visualization library based on matplotlib</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1a2034ba58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[i] Pandas .iplot() method activated.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from fsds_100719.imports import *\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "\n",
    "from keras import models, layers,optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense#,Dropout\n",
    "\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T19:10:44.486225Z",
     "start_time": "2020-02-13T19:10:44.170623Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape:\t(60000, 28, 28)\n",
      "X_test.shape:\t(10000, 28, 28)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "print(f'X_train.shape:\\t{X_train.shape}')\n",
    "print(f'X_test.shape:\\t{X_test.shape}')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T19:10:44.733663Z",
     "start_time": "2020-02-13T19:10:44.487799Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 1.0, 'Image #41885:  Label=4')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Visualize random image\n",
    "i = np.random.choice(list(range(len(X_train))))\n",
    "sample_image = X_train[i]\n",
    "sample_label = y_train[i]\n",
    "\n",
    "title = f\"Image #{i}:  Label={sample_label}\"\n",
    "plt.imshow(sample_image, cmap='gray')\n",
    "\n",
    "ax= plt.gca()\n",
    "ax.set(title=title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T19:10:44.738726Z",
     "start_time": "2020-02-13T19:10:44.735183Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n",
      "X_train.shape=(60000, 28, 28)\n",
      "X_test.shape=(10000, 28, 28)\n",
      "784\n"
     ]
    }
   ],
   "source": [
    "## Print out image shapes and data shapes\n",
    "print(sample_image.shape)\n",
    "print(f\"X_train.shape={X_train.shape}\")\n",
    "print(f\"X_test.shape={X_test.shape}\")\n",
    "print(sample_image.shape[0]*sample_image.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T19:10:44.745922Z",
     "start_time": "2020-02-13T19:10:44.739960Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X_train': (60000, 28, 28),\n",
       " 'X_test': (10000, 28, 28),\n",
       " 'y_train': (60000,),\n",
       " 'y_test': (10000,),\n",
       " 'image': (28, 28),\n",
       " 'image_flat': 784}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## SAVE SHAPES FOR EASY ACCESS LATE\n",
    "X_shapes = dict(X_train=X_train.shape,\n",
    "                X_test=X_test.shape,\n",
    "               y_train=y_train.shape,\n",
    "               y_test=y_test.shape,\n",
    "               image=sample_image.shape,\n",
    "                image_flat = sample_image.shape[0]*sample_image.shape[1]\n",
    "               )\n",
    "X_shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ***We can interpret these numbers as saying \"X_train consists of 60,000 images that are 28x28\". We'll need to reshape them from (28, 28), a 28x28 matrix, to (784,), a 784-element vector. However, we need to make sure that the first number in our reshape call for both X_train and X_test still correspond to the number of observations we have in each.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T19:10:44.751381Z",
     "start_time": "2020-02-13T19:10:44.747451Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[28, 28]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shapes = list(sample_image.shape)\n",
    "shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T19:10:45.085072Z",
     "start_time": "2020-02-13T19:10:44.753778Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "784\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_shapes = dict(X_train=X_train.shape,\n",
    "               X_test=X_test.shape,\n",
    "               y_train=y_train.shape,\n",
    "                y_test=y_test.shape,\n",
    "               image=sample_image.shape,\n",
    "               image_unrow = sample_image.shape[0]*sample_image.shape[1],)\n",
    "\n",
    "print(X_shapes['X_train'])\n",
    "print(X_shapes['image_unrow'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Targets\n",
    "\n",
    "- This is a **Multiclass Classification** problem.\n",
    "    - we need to One-Hot Encode our labels\n",
    "    - `keras.utils.to_categorical`\n",
    "    \n",
    "- For multi classification:\n",
    "    - good final activation function is softmax\n",
    "    - categorical_crossentytropu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T19:10:45.291285Z",
     "start_time": "2020-02-13T19:10:45.087217Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train original shape = (60000,)\n",
      "y_train to_categorical shape = (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "#  reshape and convert astype('float32') so that we convert our data from type uint8 to float32\n",
    "X_train = X_train.reshape(X_shapes['X_train'][0], X_shapes['image_unrow']).astype('float32')\n",
    "X_test = X_test.reshape(X_shapes['X_test'][0], X_shapes['image_unrow']).astype('float32')\n",
    "\n",
    "## normalizing data \n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "y_train_orig = y_train.copy()\n",
    "y_test_orig = y_test.copy()\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "print(f\"y_train original shape = {y_train_orig.shape}\")\n",
    "print(f\"y_train to_categorical shape = {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T19:10:45.299009Z",
     "start_time": "2020-02-13T19:10:45.293006Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Taking argmax(axis=1) of to_categorical converts it back\n",
    "all(y_train.argmax(axis=1) == y_train_orig) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T19:10:45.308201Z",
     "start_time": "2020-02-13T19:10:45.300442Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_model(y_true,y_pred=None,X=None,model=None,history=None):\n",
    "    \"\"\"Uses plot_keras_history and plot_confusion_matrix\n",
    "    to display result of keras classification.\n",
    "    Also prints the classification report.\"\"\"\n",
    "    if (y_pred is None):\n",
    "        if (X is None):\n",
    "            raise Exception('You must either provide X data + model OR y_pred.')\n",
    "        else:\n",
    "            if model is not None:\n",
    "                y_pred = model.predict_classes(X)\n",
    "            else:\n",
    "                raise Exception('If using X data you must also provide model.')\n",
    "            \n",
    "    if history is not None:\n",
    "        plot_keras_history(history)\n",
    "\n",
    "\n",
    "    ## reshape keras categorical for sklearn\n",
    "    if y_true.ndim>1:\n",
    "        y_true = y_true.argmax(axis=1)\n",
    "    if y_pred.ndim>1:\n",
    "        y_pred = y_pred.argmax(axis=1)\n",
    "\n",
    "        \n",
    "    import sklearn.metrics as metrics\n",
    "    class_report = metrics.classification_report(y_true,y_pred)\n",
    "    print(class_report)\n",
    "    \n",
    "    try:\n",
    "        fig = plot_confusion_matrix((y_true,y_pred),normalize=True)\n",
    "        display(fig)\n",
    "    except Exception as e:\n",
    "        print('Error with confusion matrix.:')\n",
    "        print(f'\\t{e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T19:10:45.326219Z",
     "start_time": "2020-02-13T19:10:45.309776Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_keras_history(history,figsize=(10,4),subplot_kws={}):\n",
    "    if hasattr(history,'history'):\n",
    "        history=history.history\n",
    "    #     history = results.history\n",
    "    fig,axes=plt.subplots(ncols=2,figsize=figsize,**subplot_kws)\n",
    "    \n",
    "    ax=axes[0]\n",
    "    ax.plot(history['val_loss'],label='val_loss')\n",
    "    ax.plot(history['loss'], label='loss')\n",
    "    ax.legend()\n",
    "    \n",
    "    ax=axes[1]\n",
    "    ax.plot(history['val_accuracy'],label='val_accuracy')\n",
    "    ax.plot(history['accuracy'], label='accuracy')\n",
    "\n",
    "    ax.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def plot_confusion_matrix(conf_matrix, classes = None, normalize=True,\n",
    "                          title='Confusion Matrix', cmap=\"Blues\",\n",
    "                          print_raw_matrix=False,\n",
    "                          fig_size=(7,8)):\n",
    "    \"\"\"Check if Normalization Option is Set to True. \n",
    "    If so, normalize the raw confusion matrix before visualizing\n",
    "    #Other code should be equivalent to your previous function.\n",
    "    Note: Taken from bs_ds and modified\n",
    "    - Can pass a tuple of (y_true,y_pred) instead of conf matrix.\n",
    "    \"\"\"\n",
    "    import itertools\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    ## make confusion matrix if given tuple of y_true,y_pred\n",
    "    if isinstance(conf_matrix, tuple):\n",
    "        y_true = conf_matrix[0].copy()\n",
    "        y_pred = conf_matrix[1].copy()\n",
    "        \n",
    "        ## collapse down to 1 dimension again\n",
    "        if y_true.ndim>1:\n",
    "            y_true = y_true.argmax(axis=1)\n",
    "        if y_pred.ndim>1:\n",
    "            y_pred = y_pred.argmax(axis=1)\n",
    "        cm = metrics.confusion_matrix(y_true,y_pred)\n",
    "        \n",
    "    else:\n",
    "        cm = conf_matrix\n",
    "        \n",
    "    ## Generate integer labels for classes\n",
    "    if classes is None:\n",
    "        classes = list(range(len(cm)))  \n",
    "        \n",
    "\n",
    "    ## Text Properties\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "\n",
    "    ## Normalize data\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "        \n",
    "    fontDict = {\n",
    "        'title':{\n",
    "            'fontsize':16,\n",
    "            'fontweight':'semibold',\n",
    "            'ha':'center',\n",
    "            },\n",
    "        'xlabel':{\n",
    "            'fontsize':14,\n",
    "            'fontweight':'normal',\n",
    "            },\n",
    "        'ylabel':{\n",
    "            'fontsize':14,\n",
    "            'fontweight':'normal',\n",
    "            },\n",
    "        'xtick_labels':{\n",
    "            'fontsize':10,\n",
    "            'fontweight':'normal',\n",
    "#             'rotation':45,\n",
    "            'ha':'right',\n",
    "            },\n",
    "        'ytick_labels':{\n",
    "            'fontsize':10,\n",
    "            'fontweight':'normal',\n",
    "            'rotation':0,\n",
    "            'ha':'right',\n",
    "            },\n",
    "        'data_labels':{\n",
    "            'ha':'center',\n",
    "            'fontweight':'semibold',\n",
    "\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "    # Create plot\n",
    "    fig,ax = plt.subplots(figsize=fig_size)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title,**fontDict['title'])\n",
    "    plt.colorbar()\n",
    "\n",
    "    tick_marks = classes#np.arange(len(classes))\n",
    "\n",
    "\n",
    "    plt.xticks(tick_marks, classes, **fontDict['xtick_labels'])\n",
    "    plt.yticks(tick_marks, classes,**fontDict['ytick_labels'])\n",
    "\n",
    "    # Determine threshold for b/w text\n",
    "    thresh = cm.max() / 2.\n",
    "\n",
    "    # fig,ax = plt.subplots()\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 color='darkgray',**fontDict['data_labels']) #color=\"white\" if cm[i, j] > thresh else \"black\"\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label',**fontDict['ylabel'])\n",
    "    plt.xlabel('Predicted label',**fontDict['xlabel'])\n",
    "\n",
    "    if print_raw_matrix:\n",
    "        print_title = 'Raw Confusion Matrix Counts:'\n",
    "        print('\\n',print_title)\n",
    "        print(conf_matrix)\n",
    "\n",
    "\n",
    "    fig = plt.gcf()\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T19:10:45.458986Z",
     "start_time": "2020-02-13T19:10:45.327661Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From //anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 52,650\n",
      "Trainable params: 52,650\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## build network\n",
    "\n",
    "## Model 3\n",
    "model3= models.Sequential()\n",
    "model3.add( \n",
    "    Dense(64, activation='relu', input_shape=(X_shapes['image_unrow'],) ))\n",
    "model3.add(Dense(32, activation='relu'))\n",
    "model3.add(Dense(10, activation='softmax'))\n",
    "\n",
    "compile_kws=dict(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "model3.compile(**compile_kws)\n",
    "\n",
    "model3.summary()\n",
    "# model.summary()\n",
    "\n",
    "model=model3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T19:10:52.258869Z",
     "start_time": "2020-02-13T19:10:45.461371Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From //anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 1.0000 - accuracy: 0.7144 - val_loss: 0.4380 - val_accuracy: 0.8803\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.3875 - accuracy: 0.8917 - val_loss: 0.3371 - val_accuracy: 0.9023\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.3229 - accuracy: 0.9077 - val_loss: 0.2923 - val_accuracy: 0.9146\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2905 - accuracy: 0.9170 - val_loss: 0.2690 - val_accuracy: 0.9217\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.2669 - accuracy: 0.9236 - val_loss: 0.2510 - val_accuracy: 0.9261\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96       980\n",
      "           1       0.96      0.98      0.97      1135\n",
      "           2       0.93      0.91      0.92      1032\n",
      "           3       0.91      0.92      0.91      1010\n",
      "           4       0.92      0.93      0.92       982\n",
      "           5       0.90      0.90      0.90       892\n",
      "           6       0.93      0.94      0.94       958\n",
      "           7       0.93      0.92      0.93      1028\n",
      "           8       0.93      0.87      0.90       974\n",
      "           9       0.91      0.90      0.91      1009\n",
      "\n",
      "    accuracy                           0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n",
      "Error with confusion matrix.:\n",
      "\tname 'metrics' is not defined\n"
     ]
    }
   ],
   "source": [
    "## Train network\n",
    "history = model.fit(X_train, y_train, batch_size=64, epochs= 5,\n",
    "                   validation_data=(X_test,y_test))\n",
    "evaluate_model(y_test,X=X_test,model=model,history=history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T19:10:52.262436Z",
     "start_time": "2020-02-13T19:10:52.260151Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot_confusion_matrix((y_test,y_hat_test));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T19:10:52.371744Z",
     "start_time": "2020-02-13T19:10:52.263879Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as metrics\n",
    "y_hat_test = model.predict_classes(X_test)\n",
    "print(y_hat_test.shape)\n",
    "print(np.array(y_hat_test).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T19:10:52.389023Z",
     "start_time": "2020-02-13T19:10:52.373412Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 964,    0,    2,    2,    0,    5,    4,    1,    2,    0],\n",
       "       [   0, 1114,    1,    3,    1,    1,    3,    2,   10,    0],\n",
       "       [  12,    8,  937,   14,   10,    2,   12,   12,   21,    4],\n",
       "       [   3,    1,   18,  928,    0,   29,    1,   15,   10,    5],\n",
       "       [   1,    5,    5,    0,  910,    1,   13,    2,    3,   42],\n",
       "       [  11,    3,    3,   32,    5,  802,   15,    3,   12,    6],\n",
       "       [  14,    3,    4,    1,   14,   15,  903,    3,    1,    0],\n",
       "       [   4,   12,   24,    5,    6,    0,    0,  945,    3,   29],\n",
       "       [   9,    8,    8,   24,   10,   32,   16,   13,  845,    9],\n",
       "       [  13,    8,    1,   10,   34,    8,    0,   16,    6,  913]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Must convert \n",
    "metrics.confusion_matrix(y_test.argmax(axis=1),y_hat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T16:24:57.597320Z",
     "start_time": "2020-02-12T16:24:57.592601Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HyperParameter Tuning with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original Source: https://chrisalbon.com/deep_learning/keras/tuning_neural_network_hyperparameters/\n",
    "<br><br>\n",
    "\n",
    "- To use `GridSearchCV` or other similar functions in scikit-learn with a Keras neural network, we need to wrap our keras model in `keras.wrappers.scikit_learn`'s `KerasClassifier` and `KerasRegressor`.\n",
    "1. To do this, we need to write a build function(`build_fn`) that creates our model such as `create_model`.\n",
    "    - This function must accept whatever parameters you wish to tune. \n",
    "    - It also must have a default argument for each parameter.\n",
    "    - This function must Return the model (and only the model)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "## Define the build function\n",
    "def create_model(n_units=(50,25,7), activation='relu',final_activation='softmax',\n",
    "                optimizer='adam'):\n",
    "    \n",
    "    ## Pro tip:save the local variables now so you can print out the parameters used to create the model.\n",
    "    params_used = locals()\n",
    "    print('Parameters for model:\\n',params_used)\n",
    "    \n",
    "   \n",
    "    from keras.models import Sequential\n",
    "    from keras import layers\n",
    "    \n",
    "    model=Sequential()\n",
    "    model.add(layers.Dense(n_units[0], activation=activation, input_shape=(2000,)))\n",
    "    model.add(layers.Dense(n_units[1], activation=activation))\n",
    "    model.add(layers.Dense(n_units[2], activation=final_activation))\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    \n",
    "    display(model.summary())\n",
    "    return model \n",
    "```    \n",
    "\n",
    "2. We then create out model using the Keras wrapper:\n",
    "\n",
    "```python\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "neural_network =  KerasClassifier(build_fn=create_model,verbose=1)\n",
    "```\n",
    "\n",
    "3. Now, set up the hyperparameter space for grid search. (Remember, your `create_model` function must accept the parameter you want to tune)\n",
    "\n",
    "```python\n",
    "params_to_test = {'n_units':[(50,25,7),(100,50,7)],\n",
    "                  'optimizer':['adam','rmsprop','adadelta'],\n",
    "                  'activation':['linear','relu','tanh'],\n",
    "                  'final_activation':['softmax']}\n",
    "```\n",
    "\n",
    "4. Now instantiate your GridSearch function\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(estimator=neural_network,param_grid=params_to_test)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "best_params = grid_result.best_params_\n",
    "```\n",
    "5. And thats it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T19:10:52.404281Z",
     "start_time": "2020-02-13T19:10:52.390317Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] Timer started at 02/13/20 - 14:10:52\n",
      "[i] Timer stopped at 02/13/20 - 14:10:52\n",
      "  - Total Time: 0:00:00.000403\n"
     ]
    }
   ],
   "source": [
    "class Timer():\n",
    "    def __init__(self, start=True,time_fmt='%m/%d/%y - %T'):\n",
    "        import tzlocal\n",
    "        import datetime as dt\n",
    "        \n",
    "        self.tz = tzlocal.get_localzone()\n",
    "        self.fmt= time_fmt\n",
    "        self._created = dt.datetime.now(tz=self.tz)\n",
    "        \n",
    "        if start:\n",
    "            self.start()\n",
    "            \n",
    "    def get_time(self):\n",
    "        import datetime as dt\n",
    "        return dt.datetime.now(tz=self.tz)\n",
    "\n",
    "        \n",
    "    def start(self,verbose=True):\n",
    "        self._laps_completed = 0\n",
    "        self.start = self.get_time()\n",
    "        if verbose: \n",
    "            print(f'[i] Timer started at {self.start.strftime(self.fmt)}')\n",
    "    \n",
    "    def stop(self, verbose=True):\n",
    "        self._laps_completed += 1\n",
    "        self.end = self.get_time()\n",
    "        self.elapsed = self.end -  self.start\n",
    "        if verbose: \n",
    "            print(f'[i] Timer stopped at {self.end.strftime(self.fmt)}')\n",
    "            print(f'  - Total Time: {self.elapsed}')\n",
    "            \n",
    "timer = Timer()\n",
    "import time\n",
    "timer.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T19:10:52.413477Z",
     "start_time": "2020-02-13T19:10:52.407640Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_model(optimizer='sgd' ,verbose=True):\n",
    "\n",
    "    model3= models.Sequential()\n",
    "    model3.add( \n",
    "        Dense(64, activation='relu', input_shape=(X_shapes['image_unrow'],) ))\n",
    "    model3.add(Dense(32, activation='relu'))\n",
    "    model3.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    compile_kws=dict()\n",
    "    model3.compile(loss='categorical_crossentropy',metrics=['accuracy'], optimizer=optimizer)\n",
    "    if verbose:\n",
    "        model3.summary()\n",
    "        \n",
    "    return model3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T19:10:52.420646Z",
     "start_time": "2020-02-13T19:10:52.415639Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras import layers, models,optimizers\n",
    "neural_network =  KerasClassifier(build_fn=build_model,verbose=1)\n",
    "leaky_relu = layers.advanced_activations.LeakyReLU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T19:11:26.306659Z",
     "start_time": "2020-02-13T19:11:11.630971Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] Timer started at 02/13/20 - 14:11:11\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 52,650\n",
      "Trainable params: 52,650\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/4\n",
      "54000/54000 [==============================] - 3s 63us/step - loss: 0.2952 - accuracy: 0.9141\n",
      "Epoch 2/4\n",
      "54000/54000 [==============================] - 3s 64us/step - loss: 0.1288 - accuracy: 0.9608\n",
      "Epoch 3/4\n",
      "54000/54000 [==============================] - 3s 63us/step - loss: 0.0958 - accuracy: 0.9712\n",
      "Epoch 4/4\n",
      "54000/54000 [==============================] - 3s 63us/step - loss: 0.0748 - accuracy: 0.9767\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multilabel-indicator and multiclass targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-2d5a2c454559>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mtimer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mgrid_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mbest_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mbest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    687\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 689\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/envs/learn-env/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/envs/learn-env/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/envs/learn-env/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/envs/learn-env/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/envs/learn-env/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/envs/learn-env/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/envs/learn-env/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    542\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0mfit_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 544\u001b[0;31m         \u001b[0mtest_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    545\u001b[0m         \u001b[0mscore_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfit_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_score\u001b[0;34m(estimator, X_test, y_test, scorer)\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m     error_msg = (\"scoring must return a number, got %s (%s) \"\n",
      "\u001b[0;32m//anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscorer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_BaseScorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m                 score = scorer._score(cached_call, estimator,\n\u001b[0;32m---> 87\u001b[0;31m                                       *args, **kwargs)\n\u001b[0m\u001b[1;32m     88\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36m_score\u001b[0;34m(self, method_caller, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             return self._sign * self._score_func(y_true, y_pred,\n\u001b[0;32m--> 212\u001b[0;31m                                                  **self._kwargs)\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0;32m---> 90\u001b[0;31m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multilabel-indicator and multiclass targets"
     ]
    }
   ],
   "source": [
    "classifier = KerasClassifier(build_fn = build_model)\n",
    "parameters = {'batch_size': [25, 32],\n",
    "              'epochs': [4],#, 20],\n",
    "              'optimizer': ['adam', 'rmsprop']}\n",
    "\n",
    "grid_search = GridSearchCV(estimator = classifier,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 10)\n",
    "\n",
    "\n",
    "timer = Timer()\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "best_parameters = grid_search.best_params_\n",
    "best_accuracy = grid_search.best_score_\n",
    "timer.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ***Ruh Roh! It doesn't seem to want to work with our data. Thats due to the scoring functions in sklearn not accepting y_data with ndim >1***\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Why would you do this?**\n",
    "    1. You may want to use a metric that isn't available in sklearn. \n",
    "        - In the included `my_custom_scorer` function, I take the accuracy of each class's predictions from the diagonal of a normalized confusion matrix. \n",
    "        - I then calculate the mean of those 3 class accuracies, which is the `score` that is returned to the gridsearch. \n",
    "        \n",
    "    2. You may want to add a printout or display to the scoring function so you can see the results as the search is going.\n",
    "<br><br>\n",
    "2. **How do you do write your own?**\n",
    "    1. Define your custom scoring function.\n",
    "        - It must accept `y_true`,`y_pred`\n",
    "        - It must return a value to maximize. (like accuracy)\n",
    "    2. You can add print or display commands to have the scoring function report the current results as the gridsearch is still going.\n",
    "        - If you combine this with the example `create_model` function above that includes the `vars=locals(); print(vars)` command, then gridsearch will display:\n",
    "            1. the parameters of each model (each time the `create_model` function is called.\n",
    "            2. The score of each model, including a confusion matrix figure (each time it calls `my_custom_scorer`).\n",
    "        \n",
    "```python\n",
    "def my_custom_scorer(y_true,y_pred):\n",
    "    \"\"\"My custom score function to use with sklearn's GridSearchCV\n",
    "    Maximizes the average accuracy per class using a normalized confusion matrix\"\"\"\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    import numpy as np\n",
    "    import functions_combined_BEST as ji    \n",
    "\n",
    "    ## Flatten one-hot encoded target columns into 1 column for sklearn functions\n",
    "    if y_true.ndim>1 or y_pred.ndim>1:\n",
    "        \n",
    "        ## reduce dimensions of y_train and y_test\n",
    "        if y_true.ndim>1:            \n",
    "            y_true = y_true.argmax(axis=1)\n",
    "        \n",
    "        if y_pred.ndim>1:\n",
    "            y_pred = y_pred.argmax(axis=1)\n",
    "\n",
    "    \n",
    "     # Get confusion matrx\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    # Normalize confusion matrix\n",
    "    cm_norm = cm.astype('float')/cm.sum(axis=1)[:,np.newaxis]\n",
    "\n",
    "    ## Get diagonals for class accuracy\n",
    "    diag = cm_norm.diagonal()\n",
    "    \n",
    "    # Get the mean of the diagonal values\n",
    "    score = np.mean(diag)\n",
    "    \n",
    "    ## Display Results for the User\n",
    "    print(f'Mean Class Accuracy = {score}')\n",
    "    print(f'Class Accuracy Values:')\n",
    "    print(diag)    \n",
    "\n",
    "    ## Plot the confusion matrix.\n",
    "    ji.plot_confusion_matrix(cm,normalize=True)\n",
    "\n",
    "    # return the score \n",
    "    return score\n",
    "```        \n",
    "        \n",
    "        \n",
    "3. **How do you use it?**\n",
    "    - When instantiating GridSearchCV pass your function as the `scoring=` parameter, wrapped in the  `sklearn.metrics.make_scorer` function.\n",
    "  \n",
    "\n",
    "```python\n",
    "## Using custom scoring function\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "grid = GridSearchCV(estimator=neural_network, \n",
    "                    param_grid=params_to_test,\n",
    "                   scoring=make_scorer(my_custom_scorer))\n",
    "                    \n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T17:11:58.415288Z",
     "start_time": "2020-02-12T17:11:58.408026Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "def my_custom_scorer(y_true,y_pred,scoring='accuracy',verbose=True):\n",
    "    \"\"\"My custom score function to use with sklearn's GridSearchCV\n",
    "    Maximizes the average accuracy per class using a normalized confusion matrix\"\"\"\n",
    "    import sklearn.metrics as metrics\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    import numpy as np\n",
    "#     import functions_combined_BEST as ji    \n",
    "#     print('\\n\\n')\n",
    "    print('---'*20)\n",
    "    ## Flatten one-hot encoded target columns into 1 column for sklearn functions\n",
    "    if y_true.ndim>1 or y_pred.ndim>1:\n",
    "        \n",
    "        ## reduce dimensions of y_train and y_test\n",
    "        if y_true.ndim>1:            \n",
    "            y_true = y_true.argmax(axis=1)\n",
    "        \n",
    "        if y_pred.ndim>1:\n",
    "            y_pred = y_pred.argmax(axis=1)\n",
    "\n",
    "    if scoring=='accuracy':\n",
    "        score =  metrics.accuracy_score(y_true,y_pred)\n",
    "    \n",
    "    elif scoring=='class_accuracy':\n",
    "        # Get confusion matr\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "        # Normalize confusion matrix\n",
    "        cm_norm = cm.astype('float')/cm.sum(axis=1)[:,np.newaxis]\n",
    "\n",
    "        ## Get diagonals for class accuracy\n",
    "        diag = cm_norm.diagonal()\n",
    "\n",
    "        # Get the mean of the diagonal values\n",
    "        score = np.mean(diag)\n",
    "\n",
    "        ## Display Results for the User\n",
    "        if verbose:\n",
    "            print(f'Mean Class Accuracy = {score}')\n",
    "            print(f'Class Accuracy Values:')\n",
    "            print(diag)    \n",
    "\n",
    "#     ## Plot the confusion matrix.\n",
    "#     fig = plot_confusion_matrix((y_true,y_pred))\n",
    "#     display(fig)\n",
    "    evaluate_model(y_true,y_pred)\n",
    " \n",
    "    print('---'*20)\n",
    "    print('\\n\\n')\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T17:14:33.427128Z",
     "start_time": "2020-02-12T17:12:09.549338Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "classifier = KerasClassifier(build_fn = build_model)\n",
    "parameters = {'batch_size': [25, 32],\n",
    "              'epochs': [10, 15],\n",
    "              'optimizer': ['adam', 'rmsprop']}\n",
    "\n",
    "grid_search = GridSearchCV(estimator = classifier,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = make_scorer(my_custom_scorer),#'accuracy',\n",
    "                           cv = 5)\n",
    "\n",
    "timer = Timer()\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "best_parameters = grid_search.best_params_\n",
    "best_accuracy = grid_search.best_score_\n",
    "timer.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T17:06:17.108505Z",
     "start_time": "2020-02-12T17:06:17.106392Z"
    }
   },
   "source": [
    "## ADDING EMAIL NOTIFICATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T17:14:40.734117Z",
     "start_time": "2020-02-12T17:14:40.730800Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_secret_password(file='/Users/jamesirving/.secret/gmail.json'):\n",
    "    with open(file) as file:\n",
    "        import json\n",
    "        gmail = json.loads(file.read())\n",
    "    # email_notification()\n",
    "    print(gmail.keys())\n",
    "    return gmail\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T17:14:50.319124Z",
     "start_time": "2020-02-12T17:14:50.314907Z"
    }
   },
   "outputs": [],
   "source": [
    "gmail = get_secret_password()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T17:14:52.371628Z",
     "start_time": "2020-02-12T17:14:52.363711Z"
    }
   },
   "outputs": [],
   "source": [
    "def email_notification(password_obj=None,subject='GridSearch Finished',msg='The GridSearch is now complete.'):\n",
    "    \"\"\"Sends email notification from gmail account using previously encrypyted password  object (an instance\n",
    "    of EncrypytedPassword). \n",
    "    Args:\n",
    "        password_obj (EncryptedPassword object): EncryptedPassword object with username/password.\n",
    "        subject (str):Text for subject line.\n",
    "        msg (str): Text for body of email. \n",
    "\n",
    "    Returns:\n",
    "        Prints `Email sent!` if email successful. \n",
    "    \"\"\"\n",
    "    ## Display instructions if no password_obj \n",
    "    if password_obj is None:\n",
    "        print('Must pass an EncrypytedPassword object.')\n",
    "        print('>> pwd_obj = EncryptedPassword(username=\"my_username\",password=\"my_password\")')\n",
    "        print('>> send_email(encrypted_password_obj=pwd_obj)')\n",
    "        raise Exception('Must pass an EncryptedPassword.')\n",
    "    if isinstance(password_obj,dict):\n",
    "        gmail_user = password_obj['username']\n",
    "        gmail_password = password_obj['password']\n",
    "    else:\n",
    "        \n",
    "        ## Get username and password from password_obj\n",
    "        gmail_user = password_obj.username\n",
    "        gmail_password = password_obj._password_\n",
    "        \n",
    "    \n",
    "    # import required packages\n",
    "    import smtplib\n",
    "    from email.mime.multipart import MIMEMultipart\n",
    "    from email.mime.text import MIMEText\n",
    "    from email import encoders\n",
    "    \n",
    "\n",
    "    ## WRITE EMAIL\n",
    "    message = MIMEMultipart()\n",
    "    message['Subject'] =subject\n",
    "    message['To'] = gmail_user\n",
    "    message['From'] = gmail_user\n",
    "    body = msg\n",
    "    message.attach(MIMEText(body,'plain'))\n",
    "    text_message = message.as_string()\n",
    "\n",
    "\n",
    "    # Send email request\n",
    "    try:\n",
    "        with  smtplib.SMTP_SSL('smtp.gmail.com',465) as server:\n",
    "            \n",
    "            server.login(gmail_user,gmail_password)\n",
    "            server.sendmail(gmail_user,gmail_user, text_message)\n",
    "            server.close()\n",
    "            print('Email sent!')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print('Something went wrong')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T17:17:42.583444Z",
     "start_time": "2020-02-12T17:17:20.926582Z"
    }
   },
   "outputs": [],
   "source": [
    "## PUTTINGN IT ALL TOGETHER\n",
    "gmail = get_secret_password()\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "classifier = KerasClassifier(build_fn = build_model)\n",
    "parameters = {'batch_size': [25, 32],\n",
    "              'epochs': [10, 15],\n",
    "              'optimizer': ['adam', 'rmsprop']}\n",
    "\n",
    "grid_search = GridSearchCV(estimator = classifier,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = make_scorer(my_custom_scorer),#'accuracy',\n",
    "                           cv = 5)\n",
    "\n",
    "timer = Timer()\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "best_parameters = grid_search.best_params_\n",
    "best_accuracy = grid_search.best_score_\n",
    "timer.stop()\n",
    "email_notification(gmail)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T16:28:26.717561Z",
     "start_time": "2020-02-12T16:28:26.643184Z"
    }
   },
   "outputs": [],
   "source": [
    "# params_to_test = {'n_units':[(50,25,7),(100,50,7)],\n",
    "#                   'optimizer':['adam','rmsprop','adadelta'],\n",
    "#                   'activation':['linear','relu','tanh'],\n",
    "#                   'final_activation':['softmax']}\n",
    "# grid = GridSearchCV(estimator=neural_network,param_grid=params_to_test)\n",
    "\n",
    "\n",
    "# grid_result = grid.fit(X_train, y_train)\n",
    "# best_params = grid_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_custom_scorer(y_true,y_pred):\n",
    "    \"\"\"My custom score function to use with sklearn's GridSearchCV\n",
    "    Maximizes the average accuracy per class using a normalized confusion matrix\"\"\"\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    import numpy as np\n",
    "    import functions_combined_BEST as ji    \n",
    "\n",
    "    ## Flatten one-hot encoded target columns into 1 column for sklearn functions\n",
    "    if y_true.ndim>1 or y_pred.ndim>1:\n",
    "        \n",
    "        ## reduce dimensions of y_train and y_test\n",
    "        if y_true.ndim>1:            \n",
    "            y_true = y_true.argmax(axis=1)\n",
    "        \n",
    "        if y_pred.ndim>1:\n",
    "            y_pred = y_pred.argmax(axis=1)\n",
    "\n",
    "    \n",
    "     # Get confusion matrx\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    # Normalize confusion matrix\n",
    "    cm_norm = cm.astype('float')/cm.sum(axis=1)[:,np.newaxis]\n",
    "\n",
    "    ## Get diagonals for class accuracy\n",
    "    diag = cm_norm.diagonal()\n",
    "    \n",
    "    # Get the mean of the diagonal values\n",
    "    score = np.mean(diag)\n",
    "    \n",
    "    ## Display Results for the User\n",
    "    print(f'Mean Class Accuracy = {score}')\n",
    "    print(f'Class Accuracy Values:')\n",
    "    print(diag)    \n",
    "\n",
    "    ## Plot the confusion matrix.\n",
    "    ji.plot_confusion_matrix(cm,normalize=True)\n",
    "\n",
    "    # return the score \n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sidebar: Augmenting Image Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 💡 Data Augmentation (not covered in class)\n",
    "- Simplest way to reduce overfitting is to increase the size of the training data.\n",
    "- Difficult to do with large datasets, but can be implemented with images as shown below:\n",
    "- **For augmenting image data:**\n",
    "    - Can alter the images already present in the training data by shifting, shearing, scaling, rotating.<br><br> <img src =\"https://www.dropbox.com/s/9i1hl3quwo294jr/data_augmentation_example.png?raw=1\" width=300>\n",
    "    - This usually provides a big leap in improving the accuracy of the model. It can be considered as a mandatory trick in order to improve our predictions.\n",
    "\n",
    "- **In Keras:**\n",
    "    - `ImageDataGenerator` contains several augmentations available.\n",
    "    - Example below:\n",
    "    \n",
    "```python\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(horizontal flip=True)\n",
    "datagen.fit(train)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END OF 02-11-2020 STUDY GROUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T16:28:31.958107Z",
     "start_time": "2020-02-12T16:28:00.245Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-11T17:02:40.083379Z",
     "start_time": "2020-02-11T17:02:40.062684Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-11T16:52:34.336107Z",
     "start_time": "2020-02-11T16:52:13.048Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C3U8KA5IPuXV"
   },
   "source": [
    "\n",
    "### Tools & Applications introduced\n",
    "- **Numpy Functions**\n",
    "    - To unrow a 3-D image ( row, cols, RGB):\n",
    "        - `image_array.shape # returns (790, 64,64,3) - 790 imgs, size = 64,64, RGB=3\n",
    "        - `img_unrow = img.reshape(len(image_array), -1).T`\n",
    "            - -1 takes care of the remaining dims\n",
    "    - To increase the 'rank' of a vector (the first dimension) \n",
    "        - `np.reshape(vector, (1,len(image_array))`\n",
    "- **Keras**\n",
    "    - `from keras import models, layers, optimizers`\n",
    "    - `keras.preprocessing.image` \n",
    "    - `keras.preprocessing.text`\n",
    "- `from matplotlib.pyplot import imread, imshow`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GKw2nWdMDKR6"
   },
   "source": [
    "## Section 42: Network Regularlization & Normalization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lbzweQKTDPTl"
   },
   "source": [
    "## Overview - Regularization\n",
    "- Bias vs variance trade-off\n",
    "- Using test, train, and vali splits. \n",
    "- Prevent overfitting by adding regularization methods (L1, L2, dropout)\n",
    "- Optimizing and training time reduction by normalizing inputs\n",
    "    - Normalizing inputs can drasticaly decrease computation time, and prevent vanishing/exploding graidents. \n",
    "    \n",
    "### Hyperparameters to Tune\n",
    "- Number of hidden units\n",
    "- Number of layers\n",
    "- Learning rate ( $\\alpha$)\n",
    "- Activation function\n",
    "\n",
    "### Training, Validation, and Test Sets\n",
    "- The fact that there are so many hyperparameters to tune calls for a formalized and unbiased approach to testing/training sets.\n",
    "- We will use 3 sets when running, selecting, and validating a model:\n",
    "    - Training set: for training the alogrithm\n",
    "    - Validation set: to decide which model will be the final one after parameter tuning\n",
    "    - Testing set: after choosing final  the final model, use the test set for an inbiased estimate of performance. \n",
    "- Set sizes:\n",
    "    - With big data, your dev and test sets don't necessarily need to be 20-30% of all the data. \n",
    "    - You can choose test and hold-out sets that are of size 1-5%. \n",
    "        - eg. 96% train, 2% hold-out, 2% test set. \n",
    "    - It is **VERY IMPORTANT** to make sure holdout and test sample come from the same distribution: eg. same resolution of santa pictures. \n",
    "    \n",
    "### Bias vs Variance \n",
    "- A model with high bias may result in underfitting.\n",
    "    - <img src=\"https://raw.githubusercontent.com/jirvingphd/dsc-04-42-02-tuning-neural-networks-with-regularization-online-ds-ft-021119/master/figures/underfitting.png\" width=200>\n",
    "- A model with high variance may result in overfitting. \n",
    "    - <img src=\"https://raw.githubusercontent.com/jirvingphd/dsc-04-42-02-tuning-neural-networks-with-regularization-online-ds-ft-021119/master/figures/overfitting.png\" width=200>\n",
    "\n",
    "- In deep learning, there is less of a bias-variance trad-off vs simpler models. \n",
    "\n",
    "**Rules of thumb re: bias/variance trade-off:**\n",
    "\n",
    "| High Bias? (training performance) | high variance? (validation performance)  |\n",
    "|---------------|-------------|\n",
    "| Use a bigger network|    More data     |\n",
    "| Train longer | Regularization   |\n",
    "| Look for other existing NN architextures |Look for other existing NN architextures |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BlPs5Wd8GrNg"
   },
   "source": [
    "### L1 & L2 Regularlization\n",
    "- These methods of regularizaiton do so by penalizing coefficients(regression) or weights(neural networks),\n",
    "    - L1 & L2 exist in regression models as well. There, L1='Lasso Regressions' , L2='Ridge regression'\n",
    "\n",
    "- **L1 & L2 regularization add a term to the cost function.**\n",
    "\n",
    "$$Cost function = Loss (say, binary cross entropy) + Regularization term$$\n",
    "\n",
    "$$ J (w^{[1]},b^{[1]},...,w^{[L]},b^{[L]}) = \\dfrac{1}{m} \\sum^m_{i=1}\\mathcal{L}(\\hat y^{(i)}, y^{(i)})+ \\dfrac{\\lambda}{2m}\\sum^L_{l=1}||w^{[l]}||^2$$\n",
    "\n",
    "    - where $\\lambda$ is the regularization parameter. \n",
    "    - The difference between  L1 vs L2 is that L1 is just the sum of the weights whereas L2 is the sum of the _square_of the weights.  \n",
    "\n",
    "- **L1 Regularization:**\n",
    "    $$ Cost function = Loss + \\frac{\\lambda}{2m} * \\sum ||w||$$\n",
    "    - Uses the absolute value of weights and may reduce the weights down to 0. \n",
    "    \n",
    "        \n",
    "- **L2 Regularization:**:\n",
    "    $$ Cost function = Loss + \\frac{\\lambda}{2m} * \\sum ||w||^2$$\n",
    "    - Also known as weight decay, as it forces weights to decay towards zero, but never exactly 0.. \n",
    "    \n",
    "-  Regularization term $||w^{[l]}||^2 _F$  is  A.K.A. The Frobenius Norm\n",
    "    - $||w^{[l]}||^2 = \\sum^{n^{[l-1]}}_{i=1} \\sum^{n^{[l]}}_{j=1} (w_{ij}^{[l]})^2$\n",
    "\n",
    "    \n",
    "- **CHOOSING L1 OR L2:**\n",
    "    - L1 is very useful when trying to compress a model. (since weights can decreae to 0)\n",
    "    - L2 is generally preferred otherwise.\n",
    "    \n",
    "- **USING L1/L2 IN KERAS:**\n",
    "    - Add a kernel_regulaizer to a  layer.\n",
    "```python \n",
    "from keras import regularizers\n",
    "model.add(Dense(64, input_dim=64, kernel_regularizer=regularizers.l2(0.01))\n",
    "```\n",
    "    - here 0.01 = $\\lambda$\n",
    "\n",
    "### Dropout Regularization\n",
    "- Uses a specified probablity to random leave out a node from a ---epoch?\n",
    "\n",
    "\n",
    "- **USING DROPOUT IN KERAS:**\n",
    "    - Dropout layers are located in keras.layers.core \n",
    "    - Specify probably of being exlcuded/dropped out.\n",
    "```python\n",
    "from keras.layers.core import Dropout\n",
    "model = Sequential()\n",
    "model.add(layers.Dense(output_dim=hidden1_num_units, input_dim=input_num_units, activation='relu'))\n",
    "model.add(layers.core.Dropout(Dropout(0.25))                              \n",
    "```\n",
    "\n",
    "### Early Stopping (not covered in class)\n",
    "- Monitor performance for decrease or plateau in performance, terminate process when given criteria is reached.\n",
    "\n",
    "- **In Keras:**\n",
    "    - Can be applied using the [callbacks function](https://keras.io/callbacks/)\n",
    "```python    \n",
    "from keras.callbacks import EarlyStopping\n",
    "EarlyStopping(monitor='val_err', patience=5)\n",
    "```\n",
    "    - 'Monitor' denotes quanitity to check\n",
    "    - 'val_err' denotes validation error\n",
    "    - 'pateience' denotes # of epochs without improvement before stopping.\n",
    "        - Be careful, as sometimes models _will_ continue to improve after a stagnant period\n",
    "\n",
    "### Reference Links I found:\n",
    "- https://www.analyticsvidhya.com/blog/2018/04/fundamentals-deep-learning-regularization-techniques/\n",
    "- http://www.chioka.in/differences-between-l1-and-l2-as-loss-function-and-regularization/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HOW TO: Custom Scoring Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T16:28:31.958642Z",
     "start_time": "2020-02-12T16:28:00.255Z"
    },
    "code_folding": [
     0,
     8
    ]
   },
   "outputs": [],
   "source": [
    "def get_secret_password(file='/Users/jamesirving/.secret/gmail.json'):\n",
    "    with open(file) as file:\n",
    "        import json\n",
    "        gmail = json.loads(file.read())\n",
    "    # email_notification()\n",
    "    print(gmail.keys())\n",
    "    return gmail\n",
    "\n",
    "def email_notification(password_obj=None,subject='GridSearch Finished',msg='The GridSearch is now complete.'):\n",
    "    \"\"\"Sends email notification from gmail account using previously encrypyted password  object (an instance\n",
    "    of EncrypytedPassword). \n",
    "    Args:\n",
    "        password_obj (EncryptedPassword object): EncryptedPassword object with username/password.\n",
    "        subject (str):Text for subject line.\n",
    "        msg (str): Text for body of email. \n",
    "\n",
    "    Returns:\n",
    "        Prints `Email sent!` if email successful. \n",
    "    \"\"\"\n",
    "    ## Display instructions if no password_obj \n",
    "    if password_obj is None:\n",
    "        print('Must pass an EncrypytedPassword object.')\n",
    "        print('>> pwd_obj = EncryptedPassword(username=\"my_username\",password=\"my_password\")')\n",
    "        print('>> send_email(encrypted_password_obj=pwd_obj)')\n",
    "        raise Exception('Must pass an EncryptedPassword.')\n",
    "    if isinstance(password_obj,dict):\n",
    "        gmail_user = password_obj['username']\n",
    "        gmail_password = password_obj['password']\n",
    "    else:\n",
    "        \n",
    "        ## Get username and password from password_obj\n",
    "        gmail_user = password_obj.username\n",
    "        gmail_password = password_obj._password_\n",
    "        \n",
    "    \n",
    "    # import required packages\n",
    "    import smtplib\n",
    "    from email.mime.multipart import MIMEMultipart\n",
    "    from email.mime.text import MIMEText\n",
    "    from email import encoders\n",
    "    \n",
    "\n",
    "    ## WRITE EMAIL\n",
    "    message = MIMEMultipart()\n",
    "    message['Subject'] =subject\n",
    "    message['To'] = gmail_user\n",
    "    message['From'] = gmail_user\n",
    "    body = msg\n",
    "    message.attach(MIMEText(body,'plain'))\n",
    "    text_message = message.as_string()\n",
    "\n",
    "\n",
    "    # Send email request\n",
    "    try:\n",
    "        with  smtplib.SMTP_SSL('smtp.gmail.com',465) as server:\n",
    "            \n",
    "            server.login(gmail_user,gmail_password)\n",
    "            server.sendmail(gmail_user,gmail_user, text_message)\n",
    "            server.close()\n",
    "            print('Email sent!')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print('Something went wrong')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T16:28:31.959437Z",
     "start_time": "2020-02-12T16:28:00.258Z"
    }
   },
   "outputs": [],
   "source": [
    "# gmail = get_secret_password()\n",
    "# email_notification(gmail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T16:28:31.960447Z",
     "start_time": "2020-02-12T16:28:00.260Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def my_custom_scorer(y_true,y_pred):\n",
    "    \"\"\"My custom score function to use with sklearn's GridSearchCV\n",
    "    Maximizes the average accuracy per class using a normalized confusion matrix\n",
    "    [i] Note: To use my_custom_scorer in GridSearch:\n",
    "    >> from sklearn.metrics import make_scorer\n",
    "    >> grid = GridSearch(estimator, parameter_grid)\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import make_scorer,confusion_matrix\n",
    "    import numpy as np\n",
    "    import functions_combined_BEST as ji    \n",
    "\n",
    "    # set labels for confusion matrix\n",
    "    labels = ['Decrease','No Change', 'Increase']\n",
    "\n",
    "    \n",
    "    ## If y_true is a multi-column one-hotted target\n",
    "    if y_true.ndim>1 or y_pred.ndim>1:\n",
    "\n",
    "        ## reduce dimensions of y_train and y_test\n",
    "        if y_true.ndim>1:            \n",
    "            y_true = y_true.argmax(axis=1)\n",
    "            \n",
    "        if y_pred.ndim>1:\n",
    "            y_pred = y_pred.argmax(axis=1)\n",
    "\n",
    "    \n",
    "    ## Get confusion matrx\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    ## Normalize confusion matrix\n",
    "    cm_norm = cm.astype('float')/cm.sum(axis=1)[:,np.newaxis]\n",
    "\n",
    "    ## Get diagonals for class accuracy\n",
    "    diag = cm_norm.diagonal()\n",
    "    score = np.mean(diag)\n",
    "    \n",
    "    \n",
    "    ## Display results for user\n",
    "    print(f'Mean Class Accuracy = {score}')\n",
    "    print(f'Class Accuracy Values:')\n",
    "    print(diag)    \n",
    "\n",
    "    ## Plot confusion matrix\n",
    "    ji.plot_confusion_matrix(cm,normalize=True,classes=labels);\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y0QuBXKwRlbc"
   },
   "source": [
    "## Overview - Network Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y0QuBXKwRlbc"
   },
   "source": [
    "### Normalization\n",
    "- Normalizing to a consistent scale (typically 0 to 1) improves performance, but also ensures the process will converge to a stable solution. \n",
    "\n",
    "- Methods:\n",
    "    - Z-Score (subtracting mean, normalize by standard deviation)\n",
    "    \n",
    "#### Reference Links\n",
    "- https://www.coursera.org/lecture/deep-neural-network/normalizing-inputs-lXv6U\n",
    "\n",
    "### Changing Initial Parameters\n",
    "- The more input features into layer $l$, the smaller we want each weight $w_i$ to be.\n",
    "- Rule of thumb:\n",
    "    - $Var(w_i) = 1/n$ or $2/n$\n",
    "- A common initilization strategy for the relu activation functions is:\n",
    "\n",
    "    * $w^{[l]}$ `= np.random.randn(shape)*np.sqrt(2/n_(l-1))`\n",
    "    \n",
    "## Optimization:\n",
    "Alternatives to gradient descent that do not oscillate as much as g.d.:\n",
    "### Gradient Descent with Momentum:\n",
    "- Comutes an exponentially weighted average of the gradients to use.\n",
    "    - will dampen oscillations and improve performance.\n",
    "- How to:\n",
    "    -  Calculate current batch's moving averages for the derivatives of $W$ and$b$\n",
    "        - Compute $V_{dw} = \\beta V_{dw} + (1-\\beta)dW$\n",
    "        - $V_{db} = \\beta V_{db} + (1-\\beta)db$ \n",
    "        - So updated terms become\n",
    "            - $W:= W- \\alpha Vdw$\n",
    "            -$b:= b- \\alpha Vdb$\n",
    "    -  Generally, $\\beta=0.9$ is a good hyperparameter value.\n",
    "    \n",
    "### RMSprop\n",
    "- \"Root mean square\" prop\n",
    "- Slow down learning in one direction and speed it up in another.\n",
    "    - In the direction where we want to learn fast, the corresponding S will be small, so dividing by a small number. \n",
    "    - In the direction where we will want to learn slow, the corresponding S will be relatively large, and updates will be smaller. \n",
    "- How to:\n",
    "    - On each iteration, use exponentially weighted average again:\n",
    "        - exponentially weighted average of the squares of the derivatives\n",
    "        - $S_{dw} = \\beta S_{dw} + (1-\\beta)dW^2$\n",
    "        - $S_{db} = \\beta S_{dw} + (1-\\beta)db^2$\n",
    "        - So that:\n",
    "            - $W:= W- \\alpha \\dfrac{dw}{\\sqrt{S_{dw}}}$\n",
    "            - $b:= b- \\alpha \\dfrac{db}{\\sqrt{S_{db}}}$\n",
    "    - Often, add small $\\epsilon$ in the denominator to make sure that you don't end up dividing by 0.\n",
    "\n",
    "\n",
    "### Adam Optimization Algorithm\n",
    "- Adaptive Moment Estimation - essentially combines both methods above.\n",
    "- Works very well in most situations.\n",
    "- How to: \n",
    "    - Initialize: $V_{dw}=0, S_{dw}=0, V_{db}=0, S_{db}=0$.\n",
    "    - For each teration: compute $dW, db$ using the current mini-batch.\n",
    "        -  $V_{dw} = \\beta_1 V_{dw} + (1-\\beta_1)dW$, $V_{db} = \\beta_1 V_{db} + (1-\\beta_1)db$ \n",
    "        -  $S_{dw} = \\beta_2 S_{dw} + (1-\\beta_2)dW^2$, $S_{db} = \\beta_2 S_{db} + (1-\\beta_2)db^2$ \n",
    "        \n",
    "- As with  momentum and then RMSprop. We need to perform a correction! This is sometimes also done in RSMprop, but definitely here too.\n",
    "    - $V^{corr}_{dw}= \\dfrac{V_{dw}}{1-\\beta_1^t}$, $V^{corr}_{db}= \\dfrac{V_{db}}{1-\\beta_1^t}$\n",
    "\n",
    "    - $S^{corr}_{dw}= \\dfrac{S_{dw}}{1-\\beta_2^t}$, $S^{corr}_{db}= \\dfrac{S_{db}}{1-\\beta_2^t}$\n",
    "\n",
    "    - $W:= W- \\alpha \\dfrac{V^{corr}_{dw}}{\\sqrt{S^{corr}_{dw}+\\epsilon}}$ and\n",
    "\n",
    "    - $b:= b- \\alpha \\dfrac{V^{corr}_{db}}{\\sqrt{S^{corr}_{db}+\\epsilon}}$ \n",
    "\n",
    "\n",
    "### Learning Rate Decay\n",
    "- Learning rate decreases across epochs.\n",
    "    - $\\alpha = \\dfrac{1}{1+\\text{decay_rate * epoch_nb}}* \\alpha_0$\n",
    "\n",
    "- other methods:\n",
    "    - $\\alpha = 0.97 ^{\\text{epoch_nb}}* \\alpha_0$ (or exponential decay)<br>OR:\n",
    "    - $\\alpha = \\dfrac{k}{\\sqrt{\\text{epoch_nb}}}* \\alpha_0$<br> OR:\n",
    "    - Manual decay.\n",
    "    \n",
    "    \n",
    "    \n",
    "### HYPERPARAMETER TUNING:\n",
    "Most important:\n",
    "- $\\alpha$\n",
    "\n",
    "Important next:\n",
    "- $\\beta$ (momentum)\n",
    "- Number of hidden units\n",
    "- mini-batch-size\n",
    "\n",
    "Finally:\n",
    "- Number of layers\n",
    "- Learning rate decay\n",
    "\n",
    "Almost never tuned:\n",
    "- $\\beta_1$, $\\beta_2$, $\\epsilon$ (Adam)\n",
    "\n",
    "- Tip: Don't use a grid, because hard to say in advance which hyperparameters will be important.\n",
    "\n",
    "\n",
    "### OPTIMIZAITON REFS:\n",
    "- https://machinelearningmastery.com/dropout-regularization-deep-learning-models-keras/\n",
    "- https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/\n",
    "- https://machinelearningmastery.com/regression-tutorial-keras-deep-learning-library-python/\n",
    "- https://stackoverflow.com/questions/37232782/nan-loss-when-training-regression-network https://www.springboard.com/blog/free-public-data-sets-data-science-project/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of James' Study Group Notes - Section 41-42 (condensed version).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "256px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
