{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extensions to Linear Models - Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this lab, you'll practice many concepts you have learned so far, from adding interactions and polynomials to your model to AIC and BIC!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You will be able to:\n",
    "- Build a linear regression model with interactions and polynomial features \n",
    "- Use AIC and BIC to select the best value for the regularization parameter \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T16:02:49.465733Z",
     "start_time": "2020-01-10T16:02:47.812153Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: fsds_100719 in /anaconda3/envs/learn-env/lib/python3.6/site-packages (0.6.4)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from fsds_100719) (0.21.3)\n",
      "Requirement already satisfied, skipping upgrade: tzlocal in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from fsds_100719) (2.0.0)\n",
      "Requirement already satisfied, skipping upgrade: pprint in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from fsds_100719) (0.1)\n",
      "Requirement already satisfied, skipping upgrade: lxml in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from fsds_100719) (4.4.1)\n",
      "Requirement already satisfied, skipping upgrade: missingno in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from fsds_100719) (0.4.2)\n",
      "Requirement already satisfied, skipping upgrade: IPython in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from fsds_100719) (7.8.0)\n",
      "Requirement already satisfied, skipping upgrade: matplotlib in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from fsds_100719) (3.1.1)\n",
      "Requirement already satisfied, skipping upgrade: selenium in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from fsds_100719) (3.141.0)\n",
      "Requirement already satisfied, skipping upgrade: pandas in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from fsds_100719) (0.25.1)\n",
      "Requirement already satisfied, skipping upgrade: pyperclip in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from fsds_100719) (1.7.0)\n",
      "Requirement already satisfied, skipping upgrade: fake-useragent in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from fsds_100719) (0.1.11)\n",
      "Requirement already satisfied, skipping upgrade: wordcloud in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from fsds_100719) (1.6.0)\n",
      "Requirement already satisfied, skipping upgrade: pandas-profiling in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from fsds_100719) (2.3.0)\n",
      "Requirement already satisfied, skipping upgrade: ipywidgets in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from fsds_100719) (7.5.1)\n",
      "Requirement already satisfied, skipping upgrade: scipy in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from fsds_100719) (1.4.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from fsds_100719) (1.16.5)\n",
      "Requirement already satisfied, skipping upgrade: seaborn in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from fsds_100719) (0.9.0)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from scikit-learn->fsds_100719) (0.13.2)\n",
      "Requirement already satisfied, skipping upgrade: pytz in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from tzlocal->fsds_100719) (2019.2)\n",
      "Requirement already satisfied, skipping upgrade: pickleshare in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from IPython->fsds_100719) (0.7.5)\n",
      "Requirement already satisfied, skipping upgrade: pexpect; sys_platform != \"win32\" in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from IPython->fsds_100719) (4.7.0)\n",
      "Requirement already satisfied, skipping upgrade: pygments in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from IPython->fsds_100719) (2.4.2)\n",
      "Requirement already satisfied, skipping upgrade: decorator in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from IPython->fsds_100719) (4.4.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=18.5 in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from IPython->fsds_100719) (41.2.0)\n",
      "Requirement already satisfied, skipping upgrade: prompt-toolkit<2.1.0,>=2.0.0 in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from IPython->fsds_100719) (2.0.9)\n",
      "Requirement already satisfied, skipping upgrade: jedi>=0.10 in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from IPython->fsds_100719) (0.15.1)\n",
      "Requirement already satisfied, skipping upgrade: appnope; sys_platform == \"darwin\" in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from IPython->fsds_100719) (0.1.0)\n",
      "Requirement already satisfied, skipping upgrade: backcall in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from IPython->fsds_100719) (0.1.0)\n",
      "Requirement already satisfied, skipping upgrade: traitlets>=4.2 in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from IPython->fsds_100719) (4.3.2)\n",
      "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from matplotlib->fsds_100719) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from matplotlib->fsds_100719) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from matplotlib->fsds_100719) (2.4.2)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from matplotlib->fsds_100719) (2.8.0)\n",
      "Requirement already satisfied, skipping upgrade: urllib3 in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from selenium->fsds_100719) (1.24.2)\n",
      "Requirement already satisfied, skipping upgrade: pillow in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from wordcloud->fsds_100719) (6.2.1)\n",
      "Requirement already satisfied, skipping upgrade: jinja2>=2.8 in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from pandas-profiling->fsds_100719) (2.10.1)\n",
      "Requirement already satisfied, skipping upgrade: htmlmin>=0.1.12 in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from pandas-profiling->fsds_100719) (0.1.12)\n",
      "Requirement already satisfied, skipping upgrade: confuse>=1.0.0 in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from pandas-profiling->fsds_100719) (1.0.0)\n",
      "Requirement already satisfied, skipping upgrade: astropy in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from pandas-profiling->fsds_100719) (3.2.3)\n",
      "Requirement already satisfied, skipping upgrade: phik>=0.9.8 in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from pandas-profiling->fsds_100719) (0.9.8)\n",
      "Requirement already satisfied, skipping upgrade: nbformat>=4.2.0 in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from ipywidgets->fsds_100719) (4.4.0)\n",
      "Requirement already satisfied, skipping upgrade: widgetsnbextension~=3.5.0 in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from ipywidgets->fsds_100719) (3.5.1)\n",
      "Requirement already satisfied, skipping upgrade: ipykernel>=4.5.1 in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from ipywidgets->fsds_100719) (5.1.2)\n",
      "Requirement already satisfied, skipping upgrade: ptyprocess>=0.5 in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from pexpect; sys_platform != \"win32\"->IPython->fsds_100719) (0.6.0)\n",
      "Requirement already satisfied, skipping upgrade: wcwidth in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from prompt-toolkit<2.1.0,>=2.0.0->IPython->fsds_100719) (0.1.7)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.9.0 in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from prompt-toolkit<2.1.0,>=2.0.0->IPython->fsds_100719) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: parso>=0.5.0 in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from jedi>=0.10->IPython->fsds_100719) (0.5.1)\n",
      "Requirement already satisfied, skipping upgrade: ipython_genutils in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from traitlets>=4.2->IPython->fsds_100719) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from jinja2>=2.8->pandas-profiling->fsds_100719) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: pyyaml in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from confuse>=1.0.0->pandas-profiling->fsds_100719) (5.1.2)\n",
      "Requirement already satisfied, skipping upgrade: pytest>=4.0.2 in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from phik>=0.9.8->pandas-profiling->fsds_100719) (5.3.0)\n",
      "Requirement already satisfied, skipping upgrade: numba>=0.38.1 in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from phik>=0.9.8->pandas-profiling->fsds_100719) (0.46.0)\n",
      "Requirement already satisfied, skipping upgrade: pytest-pylint>=0.13.0 in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from phik>=0.9.8->pandas-profiling->fsds_100719) (0.14.1)\n",
      "Requirement already satisfied, skipping upgrade: jupyter-client>=5.2.3 in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from phik>=0.9.8->pandas-profiling->fsds_100719) (5.3.3)\n",
      "Requirement already satisfied, skipping upgrade: nbconvert>=5.3.1 in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from phik>=0.9.8->pandas-profiling->fsds_100719) (5.5.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied, skipping upgrade: jsonschema!=2.5.0,>=2.4 in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from nbformat>=4.2.0->ipywidgets->fsds_100719) (3.0.2)\n",
      "Requirement already satisfied, skipping upgrade: jupyter_core in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from nbformat>=4.2.0->ipywidgets->fsds_100719) (4.5.0)\n",
      "Requirement already satisfied, skipping upgrade: notebook>=4.4.1 in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from widgetsnbextension~=3.5.0->ipywidgets->fsds_100719) (5.7.8)\n",
      "Requirement already satisfied, skipping upgrade: tornado>=4.2 in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from ipykernel>=4.5.1->ipywidgets->fsds_100719) (6.0.3)\n",
      "Requirement already satisfied, skipping upgrade: py>=1.5.0 in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling->fsds_100719) (1.8.0)\n",
      "Requirement already satisfied, skipping upgrade: pluggy<1.0,>=0.12 in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling->fsds_100719) (0.13.0)\n",
      "Requirement already satisfied, skipping upgrade: packaging in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling->fsds_100719) (19.2)\n",
      "Requirement already satisfied, skipping upgrade: more-itertools>=4.0.0 in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling->fsds_100719) (7.2.0)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata>=0.12; python_version < \"3.8\" in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling->fsds_100719) (0.23)\n",
      "Requirement already satisfied, skipping upgrade: attrs>=17.4.0 in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling->fsds_100719) (19.1.0)\n",
      "Requirement already satisfied, skipping upgrade: llvmlite>=0.30.0dev0 in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from numba>=0.38.1->phik>=0.9.8->pandas-profiling->fsds_100719) (0.30.0)\n",
      "Requirement already satisfied, skipping upgrade: pylint>=1.4.5 in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling->fsds_100719) (2.4.3)\n",
      "Requirement already satisfied, skipping upgrade: pyzmq>=13 in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from jupyter-client>=5.2.3->phik>=0.9.8->pandas-profiling->fsds_100719) (18.1.0)\n",
      "Requirement already satisfied, skipping upgrade: bleach in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling->fsds_100719) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: mistune>=0.8.1 in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling->fsds_100719) (0.8.4)\n",
      "Requirement already satisfied, skipping upgrade: defusedxml in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling->fsds_100719) (0.6.0)\n",
      "Requirement already satisfied, skipping upgrade: pandocfilters>=1.4.1 in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling->fsds_100719) (1.4.2)\n",
      "Requirement already satisfied, skipping upgrade: testpath in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling->fsds_100719) (0.4.2)\n",
      "Requirement already satisfied, skipping upgrade: entrypoints>=0.2.2 in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling->fsds_100719) (0.3)\n",
      "Requirement already satisfied, skipping upgrade: pyrsistent>=0.14.0 in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->fsds_100719) (0.14.11)\n",
      "Requirement already satisfied, skipping upgrade: terminado>=0.8.1 in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->fsds_100719) (0.8.2)\n",
      "Requirement already satisfied, skipping upgrade: prometheus-client in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->fsds_100719) (0.7.1)\n",
      "Requirement already satisfied, skipping upgrade: Send2Trash in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->fsds_100719) (1.5.0)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest>=4.0.2->phik>=0.9.8->pandas-profiling->fsds_100719) (0.6.0)\n",
      "Requirement already satisfied, skipping upgrade: astroid<2.4,>=2.3.0 in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling->fsds_100719) (2.3.2)\n",
      "Requirement already satisfied, skipping upgrade: isort<5,>=4.2.5 in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling->fsds_100719) (4.3.21)\n",
      "Requirement already satisfied, skipping upgrade: mccabe<0.7,>=0.6 in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling->fsds_100719) (0.6.1)\n",
      "Requirement already satisfied, skipping upgrade: webencodings in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from bleach->nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling->fsds_100719) (0.5.1)\n",
      "Requirement already satisfied, skipping upgrade: wrapt==1.11.* in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from astroid<2.4,>=2.3.0->pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling->fsds_100719) (1.11.2)\n",
      "Requirement already satisfied, skipping upgrade: lazy-object-proxy==1.4.* in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from astroid<2.4,>=2.3.0->pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling->fsds_100719) (1.4.3)\n",
      "Requirement already satisfied, skipping upgrade: typed-ast<1.5,>=1.4.0; implementation_name == \"cpython\" and python_version < \"3.8\" in /anaconda3/envs/learn-env/lib/python3.6/site-packages (from astroid<2.4,>=2.3.0->pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling->fsds_100719) (1.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U fsds_100719\n",
    "from fsds_100719.imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T16:02:49.472859Z",
     "start_time": "2020-01-10T16:02:49.468403Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at a baseline boston housing data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import the Boston housing dataset \n",
    "- Split the data into target (`y`) and predictors (`X`) -- ensure these both are DataFrames \n",
    "- Scale all the predictors using `scale`. Convert these scaled features into a DataFrame \n",
    "- Build at a baseline model using *scaled variables* as predictors. Use 5-fold cross-validation (set `random_state` to 1) and use the $R^2$ score to evaluate the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T16:02:49.493419Z",
     "start_time": "2020-01-10T16:02:49.474535Z"
    }
   },
   "outputs": [],
   "source": [
    "df = fs.datasets.load_boston()\n",
    "df.rename({'price':'MEDV'},axis=1,inplace=True)\n",
    "df.head()\n",
    "\n",
    "boston = load_boston()\n",
    "\n",
    "y = pd.DataFrame(boston.target,columns=['target'])\n",
    "X = pd.DataFrame(boston.data, columns=boston.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T16:02:55.632619Z",
     "start_time": "2020-01-10T16:02:55.610321Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>-0.419782</td>\n",
       "      <td>0.284830</td>\n",
       "      <td>-1.287909</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.144217</td>\n",
       "      <td>0.413672</td>\n",
       "      <td>-0.120013</td>\n",
       "      <td>0.140214</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.666608</td>\n",
       "      <td>-1.459000</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-1.075562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>21.6</td>\n",
       "      <td>-0.417339</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>0.194274</td>\n",
       "      <td>0.367166</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-0.492439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>34.7</td>\n",
       "      <td>-0.417342</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>1.282714</td>\n",
       "      <td>-0.265812</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>0.396427</td>\n",
       "      <td>-1.208727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>33.4</td>\n",
       "      <td>-0.416750</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>1.016303</td>\n",
       "      <td>-0.809889</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>0.416163</td>\n",
       "      <td>-1.361517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>36.2</td>\n",
       "      <td>-0.412482</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>1.228577</td>\n",
       "      <td>-0.511180</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-1.026501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>501</td>\n",
       "      <td>22.4</td>\n",
       "      <td>-0.413229</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>0.115738</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>0.158124</td>\n",
       "      <td>0.439316</td>\n",
       "      <td>0.018673</td>\n",
       "      <td>-0.625796</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.803212</td>\n",
       "      <td>1.176466</td>\n",
       "      <td>0.387217</td>\n",
       "      <td>-0.418147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>502</td>\n",
       "      <td>20.6</td>\n",
       "      <td>-0.415249</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>0.115738</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>0.158124</td>\n",
       "      <td>-0.234548</td>\n",
       "      <td>0.288933</td>\n",
       "      <td>-0.716639</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.803212</td>\n",
       "      <td>1.176466</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-0.500850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>503</td>\n",
       "      <td>23.9</td>\n",
       "      <td>-0.413447</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>0.115738</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>0.158124</td>\n",
       "      <td>0.984960</td>\n",
       "      <td>0.797449</td>\n",
       "      <td>-0.773684</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.803212</td>\n",
       "      <td>1.176466</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-0.983048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>504</td>\n",
       "      <td>22.0</td>\n",
       "      <td>-0.407764</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>0.115738</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>0.158124</td>\n",
       "      <td>0.725672</td>\n",
       "      <td>0.736996</td>\n",
       "      <td>-0.668437</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.803212</td>\n",
       "      <td>1.176466</td>\n",
       "      <td>0.403225</td>\n",
       "      <td>-0.865302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>505</td>\n",
       "      <td>11.9</td>\n",
       "      <td>-0.415000</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>0.115738</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>0.158124</td>\n",
       "      <td>-0.362767</td>\n",
       "      <td>0.434732</td>\n",
       "      <td>-0.613246</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.803212</td>\n",
       "      <td>1.176466</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-0.669058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     target      CRIM        ZN     INDUS      CHAS       NOX        RM  \\\n",
       "0      24.0 -0.419782  0.284830 -1.287909 -0.272599 -0.144217  0.413672   \n",
       "1      21.6 -0.417339 -0.487722 -0.593381 -0.272599 -0.740262  0.194274   \n",
       "2      34.7 -0.417342 -0.487722 -0.593381 -0.272599 -0.740262  1.282714   \n",
       "3      33.4 -0.416750 -0.487722 -1.306878 -0.272599 -0.835284  1.016303   \n",
       "4      36.2 -0.412482 -0.487722 -1.306878 -0.272599 -0.835284  1.228577   \n",
       "..      ...       ...       ...       ...       ...       ...       ...   \n",
       "501    22.4 -0.413229 -0.487722  0.115738 -0.272599  0.158124  0.439316   \n",
       "502    20.6 -0.415249 -0.487722  0.115738 -0.272599  0.158124 -0.234548   \n",
       "503    23.9 -0.413447 -0.487722  0.115738 -0.272599  0.158124  0.984960   \n",
       "504    22.0 -0.407764 -0.487722  0.115738 -0.272599  0.158124  0.725672   \n",
       "505    11.9 -0.415000 -0.487722  0.115738 -0.272599  0.158124 -0.362767   \n",
       "\n",
       "          AGE       DIS       RAD       TAX   PTRATIO         B     LSTAT  \n",
       "0   -0.120013  0.140214 -0.982843 -0.666608 -1.459000  0.441052 -1.075562  \n",
       "1    0.367166  0.557160 -0.867883 -0.987329 -0.303094  0.441052 -0.492439  \n",
       "2   -0.265812  0.557160 -0.867883 -0.987329 -0.303094  0.396427 -1.208727  \n",
       "3   -0.809889  1.077737 -0.752922 -1.106115  0.113032  0.416163 -1.361517  \n",
       "4   -0.511180  1.077737 -0.752922 -1.106115  0.113032  0.441052 -1.026501  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "501  0.018673 -0.625796 -0.982843 -0.803212  1.176466  0.387217 -0.418147  \n",
       "502  0.288933 -0.716639 -0.982843 -0.803212  1.176466  0.441052 -0.500850  \n",
       "503  0.797449 -0.773684 -0.982843 -0.803212  1.176466  0.441052 -0.983048  \n",
       "504  0.736996 -0.668437 -0.982843 -0.803212  1.176466  0.403225 -0.865302  \n",
       "505  0.434732 -0.613246 -0.982843 -0.803212  1.176466  0.441052 -0.669058  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Your code here\n",
    "# y = df['MEDV'].copy()\n",
    "# X = df.copy()\n",
    "X_scaled = pd.DataFrame(scale(X),columns=X.columns)\n",
    "all_data = pd.concat([y,X_scaled],axis=1)\n",
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T16:02:55.990429Z",
     "start_time": "2020-01-10T16:02:55.988285Z"
    }
   },
   "outputs": [],
   "source": [
    "# np.max(scale(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T16:02:56.156625Z",
     "start_time": "2020-01-10T16:02:56.154775Z"
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=42)\n",
    "# [print(x.shape) for x in [X_train,X_test,y_train,y_test ]];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T16:02:56.327460Z",
     "start_time": "2020-01-10T16:02:56.325499Z"
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T16:02:56.892099Z",
     "start_time": "2020-01-10T16:02:56.889940Z"
    }
   },
   "outputs": [],
   "source": [
    "# import sklearn.metrics as met\n",
    "\n",
    "# regression =  LinearRegression()\n",
    "# regression.fit(X_train_scaled,y_train)\n",
    "# preds = regression.predict(X_test_scaled)\n",
    "# met.r2_score(y_test,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T16:02:57.689848Z",
     "start_time": "2020-01-10T16:02:57.656749Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7176778617934925"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression = LinearRegression()\n",
    "crossval = KFold(n_splits=5,shuffle=True,random_state=1)\n",
    "\n",
    "baseline = np.mean(cross_val_score(regression,X_scaled,y,scoring='r2',cv=crossval))\n",
    "baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Include interactions\n",
    "\n",
    "Look at all the possible combinations of variables for interactions by adding interactions one by one to the baseline model. Next, evaluate that model using 5-fold cross-validation and store the $R^2$ to compare it with the baseline model.\n",
    "\n",
    "Print the 7 most important interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T16:02:58.972227Z",
     "start_time": "2020-01-10T16:02:58.967523Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('CRIM', 'ZN'),\n",
       " ('CRIM', 'INDUS'),\n",
       " ('CRIM', 'CHAS'),\n",
       " ('CRIM', 'NOX'),\n",
       " ('CRIM', 'RM'),\n",
       " ('CRIM', 'AGE'),\n",
       " ('CRIM', 'DIS'),\n",
       " ('CRIM', 'RAD'),\n",
       " ('CRIM', 'TAX'),\n",
       " ('CRIM', 'PTRATIO')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "from itertools import combinations\n",
    "combs = list(combinations(boston.feature_names,2))\n",
    "combs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T16:03:01.189886Z",
     "start_time": "2020-01-10T16:02:59.764027Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Col1</th>\n",
       "      <th>Col2</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>RM</td>\n",
       "      <td>LSTAT</td>\n",
       "      <td>0.783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>RM</td>\n",
       "      <td>TAX</td>\n",
       "      <td>0.775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>RM</td>\n",
       "      <td>RAD</td>\n",
       "      <td>0.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>RM</td>\n",
       "      <td>PTRATIO</td>\n",
       "      <td>0.764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>INDUS</td>\n",
       "      <td>RM</td>\n",
       "      <td>0.757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>NOX</td>\n",
       "      <td>RM</td>\n",
       "      <td>0.746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>RM</td>\n",
       "      <td>AGE</td>\n",
       "      <td>0.742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Col1     Col2     R2\n",
       "32     RM    LSTAT  0.783\n",
       "29     RM      TAX  0.775\n",
       "28     RM      RAD  0.770\n",
       "30     RM  PTRATIO  0.764\n",
       "14  INDUS       RM  0.757\n",
       "21    NOX       RM  0.746\n",
       "26     RM      AGE  0.742"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions = []\n",
    "\n",
    "data = X_scaled.copy()\n",
    "\n",
    "for comb in combs:\n",
    "    data['interaction'] = data[comb[0]] * data[comb[1]]\n",
    "    score = np.mean(cross_val_score(regression,data, y, scoring='r2',cv=crossval))\n",
    "    if score>baseline: \n",
    "        interactions.append((comb[0],comb[1],round(score,3)))\n",
    "interaction_df = pd.DataFrame.from_records(interactions,columns=['Col1','Col2','R2'])\n",
    "best_7 = interaction_df.sort_values('R2',ascending=False).head(7)\n",
    "best_7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write code to include the 7 most important interactions in your data set by adding 7 columns. Name the columns \"var1_var2\" with var1 and var2 the two variables in the interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T16:03:04.052239Z",
     "start_time": "2020-01-10T16:03:04.049211Z"
    }
   },
   "outputs": [],
   "source": [
    "df_inter = X_scaled.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T16:03:04.665093Z",
     "start_time": "2020-01-10T16:03:04.633237Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>RM_LSTAT</th>\n",
       "      <th>RM_TAX</th>\n",
       "      <th>RM_RAD</th>\n",
       "      <th>RM_PTRATIO</th>\n",
       "      <th>INDUS_RM</th>\n",
       "      <th>NOX_RM</th>\n",
       "      <th>RM_AGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.419782</td>\n",
       "      <td>0.284830</td>\n",
       "      <td>-1.287909</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.144217</td>\n",
       "      <td>0.413672</td>\n",
       "      <td>-0.120013</td>\n",
       "      <td>0.140214</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.666608</td>\n",
       "      <td>-1.459000</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-1.075562</td>\n",
       "      <td>-0.444930</td>\n",
       "      <td>-0.275757</td>\n",
       "      <td>-0.406574</td>\n",
       "      <td>-0.603547</td>\n",
       "      <td>-0.532772</td>\n",
       "      <td>-0.059659</td>\n",
       "      <td>-0.049646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.417339</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>0.194274</td>\n",
       "      <td>0.367166</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-0.492439</td>\n",
       "      <td>-0.095668</td>\n",
       "      <td>-0.191813</td>\n",
       "      <td>-0.168607</td>\n",
       "      <td>-0.058883</td>\n",
       "      <td>-0.115279</td>\n",
       "      <td>-0.143814</td>\n",
       "      <td>0.071331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.417342</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>1.282714</td>\n",
       "      <td>-0.265812</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>0.396427</td>\n",
       "      <td>-1.208727</td>\n",
       "      <td>-1.550451</td>\n",
       "      <td>-1.266461</td>\n",
       "      <td>-1.113245</td>\n",
       "      <td>-0.388783</td>\n",
       "      <td>-0.761138</td>\n",
       "      <td>-0.949544</td>\n",
       "      <td>-0.340960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.416750</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>1.016303</td>\n",
       "      <td>-0.809889</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>0.416163</td>\n",
       "      <td>-1.361517</td>\n",
       "      <td>-1.383713</td>\n",
       "      <td>-1.124148</td>\n",
       "      <td>-0.765197</td>\n",
       "      <td>0.114875</td>\n",
       "      <td>-1.328183</td>\n",
       "      <td>-0.848901</td>\n",
       "      <td>-0.823092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.412482</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>1.228577</td>\n",
       "      <td>-0.511180</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-1.026501</td>\n",
       "      <td>-1.261136</td>\n",
       "      <td>-1.358947</td>\n",
       "      <td>-0.925023</td>\n",
       "      <td>0.138869</td>\n",
       "      <td>-1.605599</td>\n",
       "      <td>-1.026210</td>\n",
       "      <td>-0.628023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>501</td>\n",
       "      <td>-0.413229</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>0.115738</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>0.158124</td>\n",
       "      <td>0.439316</td>\n",
       "      <td>0.018673</td>\n",
       "      <td>-0.625796</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.803212</td>\n",
       "      <td>1.176466</td>\n",
       "      <td>0.387217</td>\n",
       "      <td>-0.418147</td>\n",
       "      <td>-0.183699</td>\n",
       "      <td>-0.352864</td>\n",
       "      <td>-0.431778</td>\n",
       "      <td>0.516840</td>\n",
       "      <td>0.050846</td>\n",
       "      <td>0.069466</td>\n",
       "      <td>0.008203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>502</td>\n",
       "      <td>-0.415249</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>0.115738</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>0.158124</td>\n",
       "      <td>-0.234548</td>\n",
       "      <td>0.288933</td>\n",
       "      <td>-0.716639</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.803212</td>\n",
       "      <td>1.176466</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-0.500850</td>\n",
       "      <td>0.117473</td>\n",
       "      <td>0.188392</td>\n",
       "      <td>0.230524</td>\n",
       "      <td>-0.275937</td>\n",
       "      <td>-0.027146</td>\n",
       "      <td>-0.037088</td>\n",
       "      <td>-0.067769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>503</td>\n",
       "      <td>-0.413447</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>0.115738</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>0.158124</td>\n",
       "      <td>0.984960</td>\n",
       "      <td>0.797449</td>\n",
       "      <td>-0.773684</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.803212</td>\n",
       "      <td>1.176466</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-0.983048</td>\n",
       "      <td>-0.968263</td>\n",
       "      <td>-0.791131</td>\n",
       "      <td>-0.968061</td>\n",
       "      <td>1.158772</td>\n",
       "      <td>0.113998</td>\n",
       "      <td>0.155746</td>\n",
       "      <td>0.785456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>504</td>\n",
       "      <td>-0.407764</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>0.115738</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>0.158124</td>\n",
       "      <td>0.725672</td>\n",
       "      <td>0.736996</td>\n",
       "      <td>-0.668437</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.803212</td>\n",
       "      <td>1.176466</td>\n",
       "      <td>0.403225</td>\n",
       "      <td>-0.865302</td>\n",
       "      <td>-0.627925</td>\n",
       "      <td>-0.582868</td>\n",
       "      <td>-0.713222</td>\n",
       "      <td>0.853728</td>\n",
       "      <td>0.083988</td>\n",
       "      <td>0.114746</td>\n",
       "      <td>0.534818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>505</td>\n",
       "      <td>-0.415000</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>0.115738</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>0.158124</td>\n",
       "      <td>-0.362767</td>\n",
       "      <td>0.434732</td>\n",
       "      <td>-0.613246</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.803212</td>\n",
       "      <td>1.176466</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-0.669058</td>\n",
       "      <td>0.242712</td>\n",
       "      <td>0.291379</td>\n",
       "      <td>0.356543</td>\n",
       "      <td>-0.426783</td>\n",
       "      <td>-0.041986</td>\n",
       "      <td>-0.057362</td>\n",
       "      <td>-0.157706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CRIM        ZN     INDUS      CHAS       NOX        RM       AGE  \\\n",
       "0   -0.419782  0.284830 -1.287909 -0.272599 -0.144217  0.413672 -0.120013   \n",
       "1   -0.417339 -0.487722 -0.593381 -0.272599 -0.740262  0.194274  0.367166   \n",
       "2   -0.417342 -0.487722 -0.593381 -0.272599 -0.740262  1.282714 -0.265812   \n",
       "3   -0.416750 -0.487722 -1.306878 -0.272599 -0.835284  1.016303 -0.809889   \n",
       "4   -0.412482 -0.487722 -1.306878 -0.272599 -0.835284  1.228577 -0.511180   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "501 -0.413229 -0.487722  0.115738 -0.272599  0.158124  0.439316  0.018673   \n",
       "502 -0.415249 -0.487722  0.115738 -0.272599  0.158124 -0.234548  0.288933   \n",
       "503 -0.413447 -0.487722  0.115738 -0.272599  0.158124  0.984960  0.797449   \n",
       "504 -0.407764 -0.487722  0.115738 -0.272599  0.158124  0.725672  0.736996   \n",
       "505 -0.415000 -0.487722  0.115738 -0.272599  0.158124 -0.362767  0.434732   \n",
       "\n",
       "          DIS       RAD       TAX   PTRATIO         B     LSTAT  RM_LSTAT  \\\n",
       "0    0.140214 -0.982843 -0.666608 -1.459000  0.441052 -1.075562 -0.444930   \n",
       "1    0.557160 -0.867883 -0.987329 -0.303094  0.441052 -0.492439 -0.095668   \n",
       "2    0.557160 -0.867883 -0.987329 -0.303094  0.396427 -1.208727 -1.550451   \n",
       "3    1.077737 -0.752922 -1.106115  0.113032  0.416163 -1.361517 -1.383713   \n",
       "4    1.077737 -0.752922 -1.106115  0.113032  0.441052 -1.026501 -1.261136   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "501 -0.625796 -0.982843 -0.803212  1.176466  0.387217 -0.418147 -0.183699   \n",
       "502 -0.716639 -0.982843 -0.803212  1.176466  0.441052 -0.500850  0.117473   \n",
       "503 -0.773684 -0.982843 -0.803212  1.176466  0.441052 -0.983048 -0.968263   \n",
       "504 -0.668437 -0.982843 -0.803212  1.176466  0.403225 -0.865302 -0.627925   \n",
       "505 -0.613246 -0.982843 -0.803212  1.176466  0.441052 -0.669058  0.242712   \n",
       "\n",
       "       RM_TAX    RM_RAD  RM_PTRATIO  INDUS_RM    NOX_RM    RM_AGE  \n",
       "0   -0.275757 -0.406574   -0.603547 -0.532772 -0.059659 -0.049646  \n",
       "1   -0.191813 -0.168607   -0.058883 -0.115279 -0.143814  0.071331  \n",
       "2   -1.266461 -1.113245   -0.388783 -0.761138 -0.949544 -0.340960  \n",
       "3   -1.124148 -0.765197    0.114875 -1.328183 -0.848901 -0.823092  \n",
       "4   -1.358947 -0.925023    0.138869 -1.605599 -1.026210 -0.628023  \n",
       "..        ...       ...         ...       ...       ...       ...  \n",
       "501 -0.352864 -0.431778    0.516840  0.050846  0.069466  0.008203  \n",
       "502  0.188392  0.230524   -0.275937 -0.027146 -0.037088 -0.067769  \n",
       "503 -0.791131 -0.968061    1.158772  0.113998  0.155746  0.785456  \n",
       "504 -0.582868 -0.713222    0.853728  0.083988  0.114746  0.534818  \n",
       "505  0.291379  0.356543   -0.426783 -0.041986 -0.057362 -0.157706  \n",
       "\n",
       "[506 rows x 20 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "cols = best_7[['Col1','Col2']].values\n",
    "\n",
    "for col in cols:\n",
    "    df_inter[col[0]+'_'+col[1]] = df_inter[col[0]] * df_inter[col[1]]\n",
    "    \n",
    "df_inter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Include polynomials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try polynomials of degrees 2, 3, and 4 for each variable, in a similar way you did for interactions (by looking at your baseline model and seeing how $R^2$ increases). Do understand that when going for a polynomial of 4, the particular column is raised to the power of 2 and 3 as well in other terms. We only want to include \"pure\" polynomials, so make sure no interactions are included. We want the result to return a list that contain tuples of the form:\n",
    "\n",
    "`(var_name, degree, R2)`, so eg. `('DIS', 3, 0.732)` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T16:07:54.594709Z",
     "start_time": "2020-01-10T16:07:53.787833Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Col</th>\n",
       "      <th>Degree</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>RM</td>\n",
       "      <td>4</td>\n",
       "      <td>0.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>LSTAT</td>\n",
       "      <td>4</td>\n",
       "      <td>0.782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>RM</td>\n",
       "      <td>2</td>\n",
       "      <td>0.782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>RM</td>\n",
       "      <td>3</td>\n",
       "      <td>0.781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>LSTAT</td>\n",
       "      <td>3</td>\n",
       "      <td>0.774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>LSTAT</td>\n",
       "      <td>2</td>\n",
       "      <td>0.772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>DIS</td>\n",
       "      <td>3</td>\n",
       "      <td>0.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>DIS</td>\n",
       "      <td>2</td>\n",
       "      <td>0.732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>DIS</td>\n",
       "      <td>4</td>\n",
       "      <td>0.731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>TAX</td>\n",
       "      <td>4</td>\n",
       "      <td>0.724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Col  Degree     R2\n",
       "11     RM       4  0.800\n",
       "29  LSTAT       4  0.782\n",
       "9      RM       2  0.782\n",
       "10     RM       3  0.781\n",
       "28  LSTAT       3  0.774\n",
       "27  LSTAT       2  0.772\n",
       "16    DIS       3  0.737\n",
       "15    DIS       2  0.732\n",
       "17    DIS       4  0.731\n",
       "21    TAX       4  0.724"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "polynomials = [['Col','Degree', \"R2\"]]\n",
    "\n",
    "for col in X.columns:\n",
    "    for degree in [2,3,4]:\n",
    "        data = X_scaled.copy()\n",
    "        polyfeats = PolynomialFeatures(degree,include_bias=False)\n",
    "        X_tf = polyfeats.fit_transform(X[[col]])\n",
    "        data = pd.concat([data.drop(col, axis=1),pd.DataFrame(X_tf)], axis=1)\n",
    "        score = np.mean(cross_val_score(regression, data, y, scoring='r2', cv=crossval))\n",
    "        \n",
    "        if score > baseline: \n",
    "            polynomials.append([col, degree, round(score, 3)])\n",
    "results = fs.list2df(polynomials).sort_values('R2',ascending=False)\n",
    "\n",
    "top_10 = results.head(10)\n",
    "top_10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each variable, print out the maximum R2 possible when including Polynomials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T16:10:22.865758Z",
     "start_time": "2020-01-10T16:10:22.822004Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Col        RM\n",
       "Degree      4\n",
       "R2        0.8\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Col       LSTAT\n",
       "Degree        4\n",
       "R2        0.782\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Col         DIS\n",
       "Degree        4\n",
       "R2        0.737\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Col         TAX\n",
       "Degree        4\n",
       "R2        0.724\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Col       INDUS\n",
       "Degree        4\n",
       "R2        0.723\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Col          ZN\n",
       "Degree        4\n",
       "R2        0.723\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Col         AGE\n",
       "Degree        4\n",
       "R2        0.722\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Col         NOX\n",
       "Degree        4\n",
       "R2        0.721\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Col       PTRATIO\n",
       "Degree          3\n",
       "R2          0.721\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Col          B\n",
       "Degree       4\n",
       "R2        0.72\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Col        RAD\n",
       "Degree       4\n",
       "R2        0.72\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your code here\n",
    "for col in results['Col'].unique():\n",
    "    col_df = results.groupby('Col').get_group(col)\n",
    "    display(col_df.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which two variables seem to benefit most from adding polynomial terms?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Polynomials for the two features that seem to benefit the most, as in have the best R squared compared to the baseline model. For each of the two features, raise to the Polynomial that generates the best result. Make sure to start from the data set `df_inter` so the final data set has both interactions and polynomials in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T16:11:12.110738Z",
     "start_time": "2020-01-10T16:11:12.097318Z"
    }
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "for col in ['RM', 'LSTAT']:\n",
    "    poly = PolynomialFeatures(4, include_bias=False)\n",
    "    X_transformed = poly.fit_transform(X[[col]])\n",
    "    colnames= [col, col + '_' + '2',  col + '_' + '3', col + '_' + '4']\n",
    "    df_inter = pd.concat([df_inter.drop(col, axis=1), pd.DataFrame(X_transformed, columns=colnames)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out your final data set and make sure that your interaction terms as well as your polynomial terms are included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T16:11:32.080553Z",
     "start_time": "2020-01-10T16:11:32.060133Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>...</th>\n",
       "      <th>NOX_RM</th>\n",
       "      <th>RM_AGE</th>\n",
       "      <th>RM</th>\n",
       "      <th>RM_2</th>\n",
       "      <th>RM_3</th>\n",
       "      <th>RM_4</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>LSTAT_2</th>\n",
       "      <th>LSTAT_3</th>\n",
       "      <th>LSTAT_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.419782</td>\n",
       "      <td>0.284830</td>\n",
       "      <td>-1.287909</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.144217</td>\n",
       "      <td>-0.120013</td>\n",
       "      <td>0.140214</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.666608</td>\n",
       "      <td>-1.459000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059659</td>\n",
       "      <td>-0.049646</td>\n",
       "      <td>6.575</td>\n",
       "      <td>43.230625</td>\n",
       "      <td>284.241359</td>\n",
       "      <td>1868.886938</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.8004</td>\n",
       "      <td>123.505992</td>\n",
       "      <td>615.059840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.417339</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>0.367166</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143814</td>\n",
       "      <td>0.071331</td>\n",
       "      <td>6.421</td>\n",
       "      <td>41.229241</td>\n",
       "      <td>264.732956</td>\n",
       "      <td>1699.850313</td>\n",
       "      <td>9.14</td>\n",
       "      <td>83.5396</td>\n",
       "      <td>763.551944</td>\n",
       "      <td>6978.864768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.417342</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>-0.265812</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.949544</td>\n",
       "      <td>-0.340960</td>\n",
       "      <td>7.185</td>\n",
       "      <td>51.624225</td>\n",
       "      <td>370.920057</td>\n",
       "      <td>2665.060607</td>\n",
       "      <td>4.03</td>\n",
       "      <td>16.2409</td>\n",
       "      <td>65.450827</td>\n",
       "      <td>263.766833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.416750</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>-0.809889</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.848901</td>\n",
       "      <td>-0.823092</td>\n",
       "      <td>6.998</td>\n",
       "      <td>48.972004</td>\n",
       "      <td>342.706084</td>\n",
       "      <td>2398.257176</td>\n",
       "      <td>2.94</td>\n",
       "      <td>8.6436</td>\n",
       "      <td>25.412184</td>\n",
       "      <td>74.711821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.412482</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>-0.511180</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.026210</td>\n",
       "      <td>-0.628023</td>\n",
       "      <td>7.147</td>\n",
       "      <td>51.079609</td>\n",
       "      <td>365.065966</td>\n",
       "      <td>2609.126456</td>\n",
       "      <td>5.33</td>\n",
       "      <td>28.4089</td>\n",
       "      <td>151.419437</td>\n",
       "      <td>807.065599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CRIM        ZN     INDUS      CHAS       NOX       AGE       DIS  \\\n",
       "0 -0.419782  0.284830 -1.287909 -0.272599 -0.144217 -0.120013  0.140214   \n",
       "1 -0.417339 -0.487722 -0.593381 -0.272599 -0.740262  0.367166  0.557160   \n",
       "2 -0.417342 -0.487722 -0.593381 -0.272599 -0.740262 -0.265812  0.557160   \n",
       "3 -0.416750 -0.487722 -1.306878 -0.272599 -0.835284 -0.809889  1.077737   \n",
       "4 -0.412482 -0.487722 -1.306878 -0.272599 -0.835284 -0.511180  1.077737   \n",
       "\n",
       "        RAD       TAX   PTRATIO  ...    NOX_RM    RM_AGE     RM       RM_2  \\\n",
       "0 -0.982843 -0.666608 -1.459000  ... -0.059659 -0.049646  6.575  43.230625   \n",
       "1 -0.867883 -0.987329 -0.303094  ... -0.143814  0.071331  6.421  41.229241   \n",
       "2 -0.867883 -0.987329 -0.303094  ... -0.949544 -0.340960  7.185  51.624225   \n",
       "3 -0.752922 -1.106115  0.113032  ... -0.848901 -0.823092  6.998  48.972004   \n",
       "4 -0.752922 -1.106115  0.113032  ... -1.026210 -0.628023  7.147  51.079609   \n",
       "\n",
       "         RM_3         RM_4  LSTAT  LSTAT_2     LSTAT_3      LSTAT_4  \n",
       "0  284.241359  1868.886938   4.98  24.8004  123.505992   615.059840  \n",
       "1  264.732956  1699.850313   9.14  83.5396  763.551944  6978.864768  \n",
       "2  370.920057  2665.060607   4.03  16.2409   65.450827   263.766833  \n",
       "3  342.706084  2398.257176   2.94   8.6436   25.412184    74.711821  \n",
       "4  365.065966  2609.126456   5.33  28.4089  151.419437   807.065599  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "df_inter.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full model R-squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out the R-squared of the full model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T16:12:04.553885Z",
     "start_time": "2020-01-10T16:12:04.517569Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8061549447222885"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "full_model = np.mean(cross_val_score(regression,df_inter,y,scoring='r2',cv=crossval))\n",
    "full_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the best Lasso regularization parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You learned that when using Lasso regularization, your coefficients shrink to 0 when using a higher regularization parameter. Now the question is which value we should choose for the regularization parameter. \n",
    "\n",
    "This is where the AIC and BIC come in handy! We'll use both criteria in what follows and perform cross-validation to select an optimal value of the regularization parameter $alpha$ of the Lasso estimator.\n",
    "\n",
    "Read the page here: https://scikit-learn.org/stable/auto_examples/linear_model/plot_lasso_model_selection.html and create a similar plot as the first one listed on the page. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T16:12:20.496928Z",
     "start_time": "2020-01-10T16:12:20.494244Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LassoCV, LassoLarsCV, LassoLarsIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T16:12:42.487367Z",
     "start_time": "2020-01-10T16:12:42.258439Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your code here \n",
    "model_bic = LassoLarsIC(criterion='bic')\n",
    "model_bic.fit(df_inter, y)\n",
    "alpha_bic_ = model_bic.alpha_\n",
    "\n",
    "model_aic = LassoLarsIC(criterion='aic')\n",
    "model_aic.fit(df_inter, y)\n",
    "alpha_aic_ = model_aic.alpha_\n",
    "\n",
    "\n",
    "def plot_ic_criterion(model, name, color):\n",
    "    alpha_ = model.alpha_\n",
    "    alphas_ = model.alphas_\n",
    "    criterion_ = model.criterion_\n",
    "    plt.plot(-np.log10(alphas_), criterion_, '--', color=color, linewidth=2, label= name)\n",
    "    plt.axvline(-np.log10(alpha_), color=color, linewidth=2,\n",
    "                label='alpha for %s ' % name)\n",
    "    plt.xlabel('-log(alpha)')\n",
    "    plt.ylabel('criterion')\n",
    "\n",
    "plt.figure()\n",
    "plot_ic_criterion(model_aic, 'AIC', 'green')\n",
    "plot_ic_criterion(model_bic, 'BIC', 'blue')\n",
    "plt.legend()\n",
    "plt.title('Information-criterion for model selection');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the final result\n",
    "\n",
    "Finally, use the best value for the regularization parameter according to AIC and BIC, and compare R-squared and MSE using train-test split. Compare with the baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T16:13:47.291601Z",
     "start_time": "2020-01-10T16:13:47.288835Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T16:24:39.309600Z",
     "start_time": "2020-01-10T16:24:39.306221Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T16:25:26.140440Z",
     "start_time": "2020-01-10T16:25:26.114208Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_ceebe890_33c5_11ea_804c_4865ee12e626\" ><caption>linreg_all</caption><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Split</th>        <th class=\"col_heading level0 col1\" >Metric</th>        <th class=\"col_heading level0 col2\" >Value</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_ceebe890_33c5_11ea_804c_4865ee12e626level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_ceebe890_33c5_11ea_804c_4865ee12e626row0_col0\" class=\"data row0 col0\" >Train</td>\n",
       "                        <td id=\"T_ceebe890_33c5_11ea_804c_4865ee12e626row0_col1\" class=\"data row0 col1\" >r^2</td>\n",
       "                        <td id=\"T_ceebe890_33c5_11ea_804c_4865ee12e626row0_col2\" class=\"data row0 col2\" >0.716806</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ceebe890_33c5_11ea_804c_4865ee12e626level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_ceebe890_33c5_11ea_804c_4865ee12e626row1_col0\" class=\"data row1 col0\" >Test</td>\n",
       "                        <td id=\"T_ceebe890_33c5_11ea_804c_4865ee12e626row1_col1\" class=\"data row1 col1\" >r^2</td>\n",
       "                        <td id=\"T_ceebe890_33c5_11ea_804c_4865ee12e626row1_col2\" class=\"data row1 col2\" >0.778941</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ceebe890_33c5_11ea_804c_4865ee12e626level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_ceebe890_33c5_11ea_804c_4865ee12e626row2_col0\" class=\"data row2 col0\" >Train</td>\n",
       "                        <td id=\"T_ceebe890_33c5_11ea_804c_4865ee12e626row2_col1\" class=\"data row2 col1\" >MSE</td>\n",
       "                        <td id=\"T_ceebe890_33c5_11ea_804c_4865ee12e626row2_col2\" class=\"data row2 col2\" >22.478</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ceebe890_33c5_11ea_804c_4865ee12e626level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_ceebe890_33c5_11ea_804c_4865ee12e626row3_col0\" class=\"data row3 col0\" >Test</td>\n",
       "                        <td id=\"T_ceebe890_33c5_11ea_804c_4865ee12e626row3_col1\" class=\"data row3 col1\" >MSE</td>\n",
       "                        <td id=\"T_ceebe890_33c5_11ea_804c_4865ee12e626row3_col2\" class=\"data row3 col2\" >21.8978</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1a1cafa6a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Split X_scaled and y into training and test sets\n",
    "# Set random_state to 1\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, random_state=1)\n",
    "\n",
    "\n",
    "# Code for baseline model\n",
    "linreg_all = LinearRegression()\n",
    "linreg_all.fit(X_train,y_train)\n",
    "\n",
    "def get_res_df(reg,model=''):#,X_train=X_train,\n",
    "#                y_train=y_train,X_test=X_test,y_test=y_test):\n",
    "    res = [['Split','Metric','Value']]\n",
    "    res.append(['Train', 'r^2', reg.score(X_train, y_train)])\n",
    "    res.append(['Test', 'r^2', reg.score(X_test, y_test)])\n",
    "    res.append(['Train', 'MSE', mean_squared_error(y_train, reg.predict(X_train))])\n",
    "    res.append(['Test', 'MSE', mean_squared_error(y_test, reg.predict(X_test))])\n",
    "\n",
    "\n",
    "    # Print R2 and MSE\n",
    "    res = fs.list2df(res)\n",
    "    res.set_index(['Metric','Split']).round(3)\n",
    "    \n",
    "    if len(model)>0:\n",
    "        display(res.style.set_caption(model))\n",
    "                \n",
    "    return res\n",
    "res = get_res_df(linreg_all,'linreg_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T16:22:45.127892Z",
     "start_time": "2020-01-10T16:22:45.124158Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((506, 26), (506, 1))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inter.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T16:22:45.526923Z",
     "start_time": "2020-01-10T16:22:45.512435Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.003362657471310736, copy_X=True, fit_intercept=True,\n",
       "      max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "      random_state=None, selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split df_inter and y into training and test sets\n",
    "# Set random_state to 1\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_inter, y, random_state=1)\n",
    "\n",
    "# Code for lasso with alpha from AIC\n",
    "lasso = Lasso(alpha=model_aic.alpha_)\n",
    "lasso.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T16:22:46.081958Z",
     "start_time": "2020-01-10T16:22:46.063000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Split</th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Train</td>\n",
       "      <td>r^2</td>\n",
       "      <td>0.816333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Test</td>\n",
       "      <td>r^2</td>\n",
       "      <td>0.861259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Train</td>\n",
       "      <td>MSE</td>\n",
       "      <td>14.578238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Test</td>\n",
       "      <td>MSE</td>\n",
       "      <td>13.743428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Split Metric      Value\n",
       "0  Train    r^2   0.816333\n",
       "1   Test    r^2   0.861259\n",
       "2  Train    MSE  14.578238\n",
       "3   Test    MSE  13.743428"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_res_df(lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T16:22:04.803388Z",
     "start_time": "2020-01-10T16:22:04.788900Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T16:23:54.123684Z",
     "start_time": "2020-01-10T16:23:54.097140Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Split</th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Train</td>\n",
       "      <td>r^2</td>\n",
       "      <td>0.815328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Test</td>\n",
       "      <td>r^2</td>\n",
       "      <td>0.860731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Train</td>\n",
       "      <td>MSE</td>\n",
       "      <td>14.658014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Test</td>\n",
       "      <td>MSE</td>\n",
       "      <td>13.795787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Split Metric      Value\n",
       "0  Train    r^2   0.815328\n",
       "1   Test    r^2   0.860731\n",
       "2  Train    MSE  14.658014\n",
       "3   Test    MSE  13.795787"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code for lasso with alpha from BIC\n",
    "lasso = Lasso(alpha=model_bic.alpha_)\n",
    "lasso.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "# Print R2 and MSE\n",
    "get_res_df(lasso)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level up (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Lasso path\n",
    "\n",
    "From this section, you know that when using lasso, more parameters shrink to zero as your regularization parameter goes up. In Scikit-learn there is a function `lasso_path()` which visualizes the shrinkage of the coefficients while $alpha$ changes. Try this out yourself!\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/linear_model/plot_lasso_coordinate_descent_path.html#sphx-glr-auto-examples-linear-model-plot-lasso-coordinate-descent-path-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AIC and BIC for subset selection\n",
    "This notebook shows how you can use AIC and BIC purely for feature selection. Try this code out on our Boston housing data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://xavierbourretsicotte.github.io/subset_selection.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You now know how to create better linear models and how to use AIC and BIC for both feature selection and to optimize your regularization parameter when performing Ridge and Lasso. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
